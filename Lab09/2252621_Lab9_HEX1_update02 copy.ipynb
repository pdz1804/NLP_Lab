{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cfc6194",
   "metadata": {
    "papermill": {
     "duration": 0.003533,
     "end_time": "2025-03-21T04:40:08.220933",
     "exception": false,
     "start_time": "2025-03-21T04:40:08.217400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Home Exercise 1 on Text Classification\n",
    "\n",
    "Implement a **Recurrent Neural Network model** (**Vanilla RNN, GRU, and LSTM**) to predict whether a review is positive or negative.\n",
    "\n",
    "- **Data**: [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) (the last 10% of rows serve as the test set).\n",
    "- **Compare** the performance of the three models.\n",
    "\n",
    "**Note**: Submit only a **single Jupyter Notebook file** that can handle all tasks, including data downloading, preprocessing, model training, and model evaluation. *(Submissions that do not follow the guidelines will receive a score of 0.)*\n",
    "\n",
    "**Grading Criteria**\n",
    "\n",
    "For valid submissions, scores will be assigned based on the **leaderboard ranking** (**strictly greater**):\n",
    "\n",
    "- **Top 25%** → **10 points**\n",
    "- **25% - 50%** → **9.0 points**\n",
    "- **50% - 75%** → **8.0 points**\n",
    "- **75% - 100%** → **7.0 points**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4386c",
   "metadata": {
    "papermill": {
     "duration": 0.002645,
     "end_time": "2025-03-21T04:40:08.226686",
     "exception": false,
     "start_time": "2025-03-21T04:40:08.224041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf60fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T04:40:08.233216Z",
     "iopub.status.busy": "2025-03-21T04:40:08.232943Z",
     "iopub.status.idle": "2025-03-21T04:40:12.656928Z",
     "shell.execute_reply": "2025-03-21T04:40:12.655914Z"
    },
    "papermill": {
     "duration": 4.428867,
     "end_time": "2025-03-21T04:40:12.658347",
     "exception": false,
     "start_time": "2025-03-21T04:40:08.229480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\r\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\r\n",
      "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (0.3.9)\r\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\r\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\r\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\r\n",
      "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from kagglehub) (6.0.2)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub) (4.67.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\r\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.19.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas tensorflow scikit-learn kagglehub nltk matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bb0f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T04:40:12.667716Z",
     "iopub.status.busy": "2025-03-21T04:40:12.667484Z",
     "iopub.status.idle": "2025-03-21T04:40:26.898514Z",
     "shell.execute_reply": "2025-03-21T04:40:26.897523Z"
    },
    "papermill": {
     "duration": 14.237692,
     "end_time": "2025-03-21T04:40:26.899922",
     "exception": false,
     "start_time": "2025-03-21T04:40:12.662230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import kagglehub\n",
    "import os\n",
    "import re\n",
    "import time \n",
    "import string\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# added\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ebec67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T04:40:26.908217Z",
     "iopub.status.busy": "2025-03-21T04:40:26.907735Z",
     "iopub.status.idle": "2025-03-21T04:40:26.910893Z",
     "shell.execute_reply": "2025-03-21T04:40:26.910302Z"
    },
    "papermill": {
     "duration": 0.008517,
     "end_time": "2025-03-21T04:40:26.912197",
     "exception": false,
     "start_time": "2025-03-21T04:40:26.903680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)\n",
    "\n",
    "# # Define the dataset path (update this if needed)\n",
    "# dataset_file = os.path.join(path, \"IMDB Dataset.csv\")  # Ensure correct file name\n",
    "\n",
    "# # Load the dataset\n",
    "# df = pd.read_csv(dataset_file)\n",
    "\n",
    "# # Convert sentiments to binary labels\n",
    "# df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# # Split data\n",
    "# train_texts, test_texts, train_labels, test_labels = train_test_split(df['review'], df['sentiment'], test_size=0.1, random_state=42)\n",
    "\n",
    "# # Tokenization and padding\n",
    "# tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "# tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "# train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "# test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "# train_padded = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "# test_padded = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "# # Convert labels to numpy arrays\n",
    "# train_labels = np.array(train_labels)\n",
    "# test_labels = np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34791e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T04:40:26.919785Z",
     "iopub.status.busy": "2025-03-21T04:40:26.919562Z",
     "iopub.status.idle": "2025-03-21T04:40:45.026193Z",
     "shell.execute_reply": "2025-03-21T04:40:45.025286Z"
    },
    "papermill": {
     "duration": 18.111968,
     "end_time": "2025-03-21T04:40:45.027611",
     "exception": false,
     "start_time": "2025-03-21T04:40:26.915643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/\n",
      "Original Review: One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
      "Cleaned Review: one of the other reviewers has mentioned that after watching just 1 oz episode youll be hooked they are right as this is exactly what happened with methe first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the wordit is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to manyaryans muslims gangstas latinos christians italians irish and moreso scuffles death stares dodgy dealings and shady agreements are never far awayi would say the main appeal of the show is due to the fact that it goes where other shows wouldnt dare forget pretty pictures painted for mainstream audiences forget charm forget romanceoz doesnt mess around the first episode i ever saw struck me as so nasty it was surreal i couldnt say i was ready for it but as i watched more i developed a taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards wholl be sold out for a nickel inmates wholl kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewingthats if you can get in touch with your darker side\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Define the dataset path (update this if needed)\n",
    "dataset_file = os.path.join(path, \"IMDB Dataset.csv\")  # Ensure correct file name\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(dataset_file)\n",
    "\n",
    "# Convert sentiments to binary labels\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Define stopwords and chat word dictionary\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "chat_words = {\n",
    "    \"afaik\": \"as far as i know\", \"afk\": \"away from keyboard\", \"asap\": \"as soon as possible\",\n",
    "    \"lol\": \"laughing out loud\", \"imho\": \"in my honest opinion\", \"fyi\": \"for your information\",\n",
    "    \"brb\": \"be right back\", \"btw\": \"by the way\", \"idk\": \"i don't know\", \"ttyl\": \"talk to you later\",\n",
    "    \"omg\": \"oh my god\", \"gtg\": \"got to go\", \"wtf\": \"what the f...\", \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"u\": \"you\", \"bff\": \"best friends forever\", \"cya\": \"see you\", \"jk\": \"just kidding\",\n",
    "    \"idc\": \"i don't care\", \"ily\": \"i love you\", \"imu\": \"i miss you\"\n",
    "}\n",
    "\n",
    "# Function to expand chat words\n",
    "def expand_chat_words(text, chat_words_dict):\n",
    "    words = text.split()\n",
    "    expanded_text = \" \".join([chat_words_dict.get(word.upper(), word) for word in words])\n",
    "    return expanded_text\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.sub('<[^<]+?>', '', text)\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove punctuations\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    # Expand chat words\n",
    "    text = expand_chat_words(text, chat_words)\n",
    "\n",
    "    # Remove stopwords\n",
    "    # text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "df[\"cleaned_review\"] = df[\"review\"].apply(preprocess_text)\n",
    "\n",
    "# Split data\n",
    "# train_texts, test_texts, train_labels, test_labels = train_test_split(df[\"cleaned_review\"], df[\"sentiment\"], test_size=0.1, random_state=42)\n",
    "# Use the last 10% of the data as the test set (no shuffling)\n",
    "split_index = int(len(df) * 0.9)\n",
    "train_texts = df[\"cleaned_review\"].iloc[:split_index]\n",
    "test_texts = df[\"cleaned_review\"].iloc[split_index:]\n",
    "train_labels = df[\"sentiment\"].iloc[:split_index]\n",
    "test_labels = df[\"sentiment\"].iloc[split_index:]\n",
    "\n",
    "# Tokenization and padding\n",
    "MAX_VOCAB_SIZE = 10000\n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "# Convert labels to numpy arrays\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Split the training data into training and validation sets (80% - 20%)\n",
    "train_padded, val_padded, train_labels, val_labels = train_test_split(\n",
    "    train_padded, train_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Print the sizes of each set\n",
    "print(f\"Train size: {len(train_padded)}\")\n",
    "print(f\"Validation size: {len(val_padded)}\")\n",
    "print(f\"Test size (untouched): {len(test_padded)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de53f985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e56b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Weight matrices and biases\n",
    "        self.Wx = nn.Linear(embedding_dim, hidden_size, bias=False)  # Shape: (hidden_size, embedding_dim)\n",
    "        self.Wh = nn.Linear(hidden_size, hidden_size)  # Shape: (hidden_size, hidden_size)\n",
    "        self.Wy = nn.Linear(hidden_size, output_size)  # Shape: (output_size, hidden_size)\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # Shape: (batch_size, seq_len, embedding_dim)\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        h = torch.zeros(batch_size, self.hidden_size).to(x.device)  # Initial hidden state\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]  # Shape: (batch_size, embedding_dim)\n",
    "            h = self.tanh(self.Wx(x_t) + self.Wh(h))  # Shape: (batch_size, hidden_size)\n",
    "        \n",
    "        out = self.Wy(h)  # Shape: (batch_size, output_size)\n",
    "        return self.sigmoid(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6826c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
    "        super(GRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Weight matrices for GRU\n",
    "        self.Wz = nn.Linear(embedding_dim + hidden_size, hidden_size)  # Update gate\n",
    "        self.Wr = nn.Linear(embedding_dim + hidden_size, hidden_size)  # Reset gate\n",
    "        self.Wh = nn.Linear(embedding_dim + hidden_size, hidden_size)  # Candidate hidden state\n",
    "        self.Wy = nn.Linear(hidden_size, output_size)  # Output layer\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Input tensor of shape (batch_size, seq_len)\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)  # Shape: (batch_size, seq_len, embedding_dim)\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        h = torch.zeros(batch_size, self.hidden_size).to(x.device)  # Initial hidden state of shape (batch_size, hidden_size)\n",
    "        \n",
    "        for t in range(seq_len):  # Loop through each time step\n",
    "            x_t = x[:, t, :]  # Shape: (batch_size, embedding_dim)\n",
    "            \n",
    "            # Concatenate input and previous hidden state\n",
    "            hx = torch.cat((x_t, h), dim=1)  # Shape: (batch_size, embedding_dim + hidden_size)\n",
    "            \n",
    "            # Compute gates\n",
    "            z = self.sigmoid(self.Wz(hx))  # Update gate. Shape: (batch_size, hidden_size)\n",
    "            r = self.sigmoid(self.Wr(hx))  # Reset gate. Shape: (batch_size, hidden_size)\n",
    "            \n",
    "            # Compute candidate hidden state\n",
    "            rh = torch.cat((x_t, r * h), dim=1)  # Shape: (batch_size, embedding_dim + hidden_size)\n",
    "            h_hat = self.tanh(self.Wh(rh))  # Candidate hidden state. Shape: (batch_size, hidden_size)\n",
    "            \n",
    "            # Compute new hidden state\n",
    "            h = (1 - z) * h + z * h_hat  # Shape: (batch_size, hidden_size)\n",
    "        \n",
    "        out = self.Wy(h)  # Shape: (batch_size, output_size)\n",
    "        return self.sigmoid(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # Embedding layer to convert word indices to dense vectors\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Hidden state size of the LSTM\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Weight matrices for gates and candidate cell state\n",
    "        self.Wf = nn.Linear(embedding_dim + hidden_size, hidden_size)  # Forget gate\n",
    "        self.Wi = nn.Linear(embedding_dim + hidden_size, hidden_size)  # Input gate\n",
    "        self.Wo = nn.Linear(embedding_dim + hidden_size, hidden_size)  # Output gate\n",
    "        self.Wc = nn.Linear(embedding_dim + hidden_size, hidden_size)  # Candidate cell state\n",
    "        \n",
    "        # Output layer\n",
    "        self.Wy = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for LSTM model\n",
    "        \n",
    "        Arguments:\n",
    "        x -- Input tensor of shape (batch_size, seq_len)\n",
    "        \n",
    "        Returns:\n",
    "        out -- Output tensor of shape (batch_size, output_size)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Embedding layer transforms input indices to dense vectors\n",
    "        x = self.embedding(x)  # Shape: (batch_size, seq_len, embedding_dim)\n",
    "        \n",
    "        # Get batch size and sequence length from input\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # Initialize hidden state and cell state with zeros\n",
    "        h = torch.zeros(batch_size, self.hidden_size).to(x.device)  # Shape: (batch_size, hidden_size)\n",
    "        c = torch.zeros(batch_size, self.hidden_size).to(x.device)  # Shape: (batch_size, hidden_size)\n",
    "        \n",
    "        for t in range(seq_len):  # Iterate over each time step\n",
    "            x_t = x[:, t, :]  # Extract the embedding for the current time step. Shape: (batch_size, embedding_dim)\n",
    "            \n",
    "            # Concatenate input and hidden state\n",
    "            hx = torch.cat((x_t, h), dim=1)  # Shape: (batch_size, embedding_dim + hidden_size)\n",
    "            \n",
    "            # Forget gate: Decide what to forget from the cell state\n",
    "            f = self.sigmoid(self.Wf(hx))  # Shape: (batch_size, hidden_size)\n",
    "            \n",
    "            # Input gate: Decide what information to add to the cell state\n",
    "            i = self.sigmoid(self.Wi(hx))  # Shape: (batch_size, hidden_size)\n",
    "            \n",
    "            # Output gate: Decide what part of the cell state to output\n",
    "            o = self.sigmoid(self.Wo(hx))  # Shape: (batch_size, hidden_size)\n",
    "            \n",
    "            # Candidate cell state\n",
    "            c_hat = self.tanh(self.Wc(hx))  # Shape: (batch_size, hidden_size)\n",
    "            \n",
    "            # Update cell state: Combining forget gate, input gate, and candidate cell state\n",
    "            c = f * c + i * c_hat  # Shape: (batch_size, hidden_size)\n",
    "            \n",
    "            # Compute the new hidden state\n",
    "            h = o * self.tanh(c)  # Shape: (batch_size, hidden_size)\n",
    "        \n",
    "        # Compute final output through a dense layer\n",
    "        out = self.Wy(h)  # Shape: (batch_size, output_size)\n",
    "        \n",
    "        # Apply sigmoid activation for binary classification\n",
    "        return self.sigmoid(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938bb85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model Hyperparameters\n",
    "VOCAB_SIZE = min(len(tokenizer.word_index) + 1, MAX_VOCAB_SIZE)\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_SIZE = 64\n",
    "OUTPUT_SIZE = 1\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDatasets\n",
    "train_data = TensorDataset(torch.tensor(train_padded, dtype=torch.long), torch.tensor(train_labels, dtype=torch.float32))\n",
    "val_data = TensorDataset(torch.tensor(val_padded, dtype=torch.long), torch.tensor(val_labels, dtype=torch.float32))\n",
    "test_data = TensorDataset(torch.tensor(test_padded, dtype=torch.long), torch.tensor(test_labels, dtype=torch.float32))\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4387916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, val_loader, epochs, learning_rate, model_name):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            all_preds.extend((outputs > 0.5).cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracy = accuracy_score(all_labels, all_preds)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                all_preds.extend((outputs > 0.5).cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} - Train Acc: {train_accuracy:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} - Val Acc: {val_accuracy:.4f}\")\n",
    "    \n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, model_name):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs).squeeze()\n",
    "            all_preds.extend((outputs > 0.5).cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"\\nTest Performance for {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb27a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_and_validation(history_dict, metric_index, ylabel):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model_name, history in history_dict.items():\n",
    "        metric = history[metric_index]\n",
    "        val_metric = history[metric_index + 1]\n",
    "        \n",
    "        plt.plot(metric, label=f'{model_name} - Train')\n",
    "        plt.plot(val_metric, label=f'{model_name} - Validation', linestyle='--')\n",
    "    \n",
    "    plt.title(f'Training and Validation {ylabel}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Vanilla RNN\": VanillaRNN(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_SIZE, OUTPUT_SIZE),\n",
    "    \"GRU\": GRU(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_SIZE, OUTPUT_SIZE),\n",
    "    \"LSTM\": LSTM(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "}\n",
    "\n",
    "history_dict = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    history = train_and_validate(model, train_loader, val_loader, EPOCHS, LEARNING_RATE, name)\n",
    "    history_dict[name] = history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f883f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss\n",
    "plot_training_and_validation(history_dict, 0, 'Loss')\n",
    "\n",
    "# Plot Accuracy\n",
    "plot_training_and_validation(history_dict, 2, 'Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3804e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluating {name} on the Test Set...\")\n",
    "    test_metrics = evaluate_model(model, test_loader, name)\n",
    "    test_results[name] = test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459036f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5da177b6",
   "metadata": {
    "papermill": {
     "duration": 0.516613,
     "end_time": "2025-03-21T04:51:32.893378",
     "exception": false,
     "start_time": "2025-03-21T04:51:32.376765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Comparison of RNN, GRU, and LSTM Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5499c1cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T04:51:33.954413Z",
     "iopub.status.busy": "2025-03-21T04:51:33.954063Z",
     "iopub.status.idle": "2025-03-21T04:51:33.975243Z",
     "shell.execute_reply": "2025-03-21T04:51:33.974326Z"
    },
    "papermill": {
     "duration": 0.573979,
     "end_time": "2025-03-21T04:51:33.976774",
     "exception": false,
     "start_time": "2025-03-21T04:51:33.402795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Inference Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vanilla RNN</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.531807</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.471251</td>\n",
       "      <td>1.480807</td>\n",
       "      <td>291.630708</td>\n",
       "      <td>1.986262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>0.863997</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.851038</td>\n",
       "      <td>0.897509</td>\n",
       "      <td>174.433492</td>\n",
       "      <td>0.788113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.8486</td>\n",
       "      <td>0.852905</td>\n",
       "      <td>0.838057</td>\n",
       "      <td>0.845416</td>\n",
       "      <td>0.828926</td>\n",
       "      <td>173.513572</td>\n",
       "      <td>0.841296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Accuracy  Precision    Recall  F1-Score      Loss  \\\n",
       "0  Vanilla RNN    0.5310   0.531807  0.423077  0.471251  1.480807   \n",
       "1          GRU    0.8550   0.863997  0.838462  0.851038  0.897509   \n",
       "2         LSTM    0.8486   0.852905  0.838057  0.845416  0.828926   \n",
       "\n",
       "   Training Time (s)  Inference Time (s)  \n",
       "0         291.630708            1.986262  \n",
       "1         174.433492            0.788113  \n",
       "2         173.513572            0.841296  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile results into a DataFrame\n",
    "results = []\n",
    "\n",
    "for name, metrics in test_results.items():\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": metrics[0],\n",
    "        \"Precision\": metrics[1],\n",
    "        \"Recall\": metrics[2],\n",
    "        \"F1-Score\": metrics[3],\n",
    "        \"Loss\": history_dict[name][1][-1],  # Final validation loss\n",
    "        \"Training Time (s)\": sum(history_dict[name][0]),  # Sum of training times per epoch\n",
    "        \"Inference Time (s)\": sum(history_dict[name][1])  # Sum of inference times per epoch\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.head()\n",
    "\n",
    "# Save the full results to CSV\n",
    "results_csv_path = os.path.join(os.getcwd(), \"imdb_models_performance.csv\")\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "print(f\"Models performance saved to: {results_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dc6ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T04:51:35.038943Z",
     "iopub.status.busy": "2025-03-21T04:51:35.038402Z",
     "iopub.status.idle": "2025-03-21T04:51:35.049945Z",
     "shell.execute_reply": "2025-03-21T04:51:35.048890Z"
    },
    "papermill": {
     "duration": 0.575878,
     "end_time": "2025-03-21T04:51:35.051713",
     "exception": false,
     "start_time": "2025-03-21T04:51:34.475835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models performance saved to: /kaggle/working/imdb_models_performance.csv\n"
     ]
    }
   ],
   "source": [
    "# Find the best model for each metric\n",
    "best_models = {}\n",
    "\n",
    "for metric in [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Loss\", \"Training Time (s)\", \"Inference Time (s)\"]:\n",
    "    if metric in [\"Loss\", \"Training Time (s)\", \"Inference Time (s)\"]:\n",
    "        best_models[metric] = results_df.loc[results_df[metric].idxmin(), [\"Model\", metric]].to_dict()\n",
    "    else:\n",
    "        best_models[metric] = results_df.loc[results_df[metric].idxmax(), [\"Model\", metric]].to_dict()\n",
    "\n",
    "# Convert best models dictionary to DataFrame\n",
    "best_models_df = pd.DataFrame(best_models).T.reset_index().rename(columns={\"index\": \"Metric\", \"Model\": \"Best Model\", 0: \"Best Value\"})\n",
    "best_models_df.head(10)\n",
    "\n",
    "# Save the best models per metric to CSV\n",
    "best_models_csv_path = os.path.join(os.getcwd(), \"imdb_best_models_per_metric.csv\")\n",
    "best_models_df.to_csv(best_models_csv_path, index=False)\n",
    "print(f\"Best models per metric saved to: {best_models_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5465499a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T04:51:36.098572Z",
     "iopub.status.busy": "2025-03-21T04:51:36.098273Z",
     "iopub.status.idle": "2025-03-21T04:51:36.116955Z",
     "shell.execute_reply": "2025-03-21T04:51:36.116266Z"
    },
    "papermill": {
     "duration": 0.567209,
     "end_time": "2025-03-21T04:51:36.118222",
     "exception": false,
     "start_time": "2025-03-21T04:51:35.551013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Best Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Training Time (s)</th>\n",
       "      <th>Inference Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>GRU</td>\n",
       "      <td>0.855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>GRU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.863997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>GRU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>GRU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.851038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Loss</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Training Time (s)</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>173.513572</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Inference Time (s)</td>\n",
       "      <td>GRU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Metric Best Model Accuracy Precision    Recall  F1-Score  \\\n",
       "0            Accuracy        GRU    0.855       NaN       NaN       NaN   \n",
       "1           Precision        GRU      NaN  0.863997       NaN       NaN   \n",
       "2              Recall        GRU      NaN       NaN  0.838462       NaN   \n",
       "3            F1-Score        GRU      NaN       NaN       NaN  0.851038   \n",
       "4                Loss       LSTM      NaN       NaN       NaN       NaN   \n",
       "5   Training Time (s)       LSTM      NaN       NaN       NaN       NaN   \n",
       "6  Inference Time (s)        GRU      NaN       NaN       NaN       NaN   \n",
       "\n",
       "       Loss Training Time (s) Inference Time (s)  \n",
       "0       NaN               NaN                NaN  \n",
       "1       NaN               NaN                NaN  \n",
       "2       NaN               NaN                NaN  \n",
       "3       NaN               NaN                NaN  \n",
       "4  0.828926               NaN                NaN  \n",
       "5       NaN        173.513572                NaN  \n",
       "6       NaN               NaN           0.788113  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92827c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T04:51:37.124079Z",
     "iopub.status.busy": "2025-03-21T04:51:37.123514Z",
     "iopub.status.idle": "2025-03-21T04:51:37.129487Z",
     "shell.execute_reply": "2025-03-21T04:51:37.128762Z"
    },
    "papermill": {
     "duration": 0.515759,
     "end_time": "2025-03-21T04:51:37.130772",
     "exception": false,
     "start_time": "2025-03-21T04:51:36.615013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best models per metric saved to: /kaggle/working/imdb_best_models_per_metric.csv\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 134715,
     "sourceId": 320111,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 695.128767,
   "end_time": "2025-03-21T04:51:40.806272",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-21T04:40:05.677505",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
