{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Exercise 1 on Text Classification\n",
    "\n",
    "Implement a **Recurrent Neural Network model** (**Vanilla RNN, GRU, and LSTM**) to predict whether a review is positive or negative.\n",
    "\n",
    "- **Data**: [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) (the last 10% of rows serve as the test set).\n",
    "- **Compare** the performance of the three models.\n",
    "\n",
    "**Note**: Submit only a **single Jupyter Notebook file** that can handle all tasks, including data downloading, preprocessing, model training, and model evaluation. *(Submissions that do not follow the guidelines will receive a score of 0.)*\n",
    "\n",
    "**Grading Criteria**\n",
    "\n",
    "For valid submissions, scores will be assigned based on the **leaderboard ranking** (**strictly greater**):\n",
    "\n",
    "- **Top 25%** → **10 points**\n",
    "- **25% - 50%** → **9.0 points**\n",
    "- **50% - 75%** → **8.0 points**\n",
    "- **75% - 100%** → **7.0 points**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: tensorflow in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: scikit-learn in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\anaconda3\\envs\\ml_env_test\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cipy (e:\\anaconda3\\envs\\ml_env_test\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (e:\\anaconda3\\envs\\ml_env_test\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (e:\\anaconda3\\envs\\ml_env_test\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas tensorflow scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\ml_env_test\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import kagglehub\n",
    "import os\n",
    "import time \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, GRU, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define constants\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "EMBEDDING_DIM = 100\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.8).\n",
      "Path to dataset files: C:\\Users\\User\\.cache\\kagglehub\\datasets\\lakshmi25npathi\\imdb-dataset-of-50k-movie-reviews\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Define the dataset path (update this if needed)\n",
    "dataset_file = os.path.join(path, \"IMDB Dataset.csv\")  # Ensure correct file name\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(dataset_file)\n",
    "\n",
    "# Convert sentiments to binary labels\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Split data\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df['review'], df['sentiment'], test_size=0.1, random_state=42)\n",
    "\n",
    "# Tokenization and padding\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "# Convert labels to numpy arrays\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to build models\n",
    "def build_rnn_model():\n",
    "    model = Sequential([\n",
    "        Embedding(MAX_VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
    "        SimpleRNN(64, return_sequences=False),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_gru_model():\n",
    "    model = Sequential([\n",
    "        Embedding(MAX_VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
    "        GRU(64, return_sequences=False),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_lstm_model():\n",
    "    model = Sequential([\n",
    "        Embedding(MAX_VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
    "        LSTM(64, return_sequences=False),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\ml_env_test\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models\n",
    "models = {\n",
    "    \"Vanilla RNN\": build_rnn_model(),\n",
    "    \"GRU\": build_gru_model(),\n",
    "    \"LSTM\": build_lstm_model()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Vanilla RNN...\n",
      "Epoch 1/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 156ms/step - accuracy: 0.5067 - loss: 0.7094 - val_accuracy: 0.4994 - val_loss: 0.6937\n",
      "Epoch 2/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 113ms/step - accuracy: 0.5381 - loss: 0.6859 - val_accuracy: 0.5002 - val_loss: 0.6946\n",
      "Epoch 3/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 84ms/step - accuracy: 0.6384 - loss: 0.6107 - val_accuracy: 0.5036 - val_loss: 0.7560\n",
      "Epoch 4/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 177ms/step - accuracy: 0.7207 - loss: 0.4507 - val_accuracy: 0.5158 - val_loss: 0.8559\n",
      "Epoch 5/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 149ms/step - accuracy: 0.7462 - loss: 0.3978 - val_accuracy: 0.5096 - val_loss: 0.9913\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step\n",
      "\n",
      "Training GRU...\n",
      "Epoch 1/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 291ms/step - accuracy: 0.5134 - loss: 0.6916 - val_accuracy: 0.7602 - val_loss: 0.5453\n",
      "Epoch 2/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 243ms/step - accuracy: 0.7510 - loss: 0.5304 - val_accuracy: 0.8662 - val_loss: 0.3246\n",
      "Epoch 3/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 288ms/step - accuracy: 0.9051 - loss: 0.2502 - val_accuracy: 0.8884 - val_loss: 0.2698\n",
      "Epoch 4/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 277ms/step - accuracy: 0.9494 - loss: 0.1458 - val_accuracy: 0.8886 - val_loss: 0.2959\n",
      "Epoch 5/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 268ms/step - accuracy: 0.9747 - loss: 0.0828 - val_accuracy: 0.8828 - val_loss: 0.3700\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step\n",
      "\n",
      "Training LSTM...\n",
      "Epoch 1/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 246ms/step - accuracy: 0.5223 - loss: 0.6925 - val_accuracy: 0.5282 - val_loss: 0.6899\n",
      "Epoch 2/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 220ms/step - accuracy: 0.5667 - loss: 0.6773 - val_accuracy: 0.5398 - val_loss: 0.6832\n",
      "Epoch 3/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 223ms/step - accuracy: 0.6495 - loss: 0.6158 - val_accuracy: 0.8114 - val_loss: 0.4841\n",
      "Epoch 4/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 284ms/step - accuracy: 0.8423 - loss: 0.4155 - val_accuracy: 0.8210 - val_loss: 0.4578\n",
      "Epoch 5/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 287ms/step - accuracy: 0.8759 - loss: 0.3412 - val_accuracy: 0.8620 - val_loss: 0.3386\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 80ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train, evaluate and compare\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    start_train = time.time()\n",
    "    history = model.fit(\n",
    "        train_padded, train_labels,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(test_padded, test_labels),\n",
    "        verbose=1\n",
    "    )\n",
    "    end_train = time.time()\n",
    "\n",
    "    # Evaluation\n",
    "    start_pred = time.time()\n",
    "    predictions = (model.predict(test_padded) > 0.5).astype(\"int32\")\n",
    "    end_pred = time.time()\n",
    "\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions)\n",
    "    recall = recall_score(test_labels, predictions)\n",
    "    f1 = f1_score(test_labels, predictions)\n",
    "    loss = history.history['val_loss'][-1]\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1,\n",
    "        \"Loss\": loss,\n",
    "        \"Training Time (s)\": end_train - start_train,\n",
    "        \"Inference Time (s)\": end_pred - start_pred\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1-Score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8e9b309f-e7b0-4840-8475-ed250ed7ef3a",
       "rows": [
        [
         "0",
         "0.5096",
         "0.5103172158915923",
         "0.6578007145692735",
         "0.5747485258411377"
        ],
        [
         "1",
         "0.8828",
         "0.8901897456600727",
         "0.8753473600635173",
         "0.8827061649319455"
        ],
        [
         "2",
         "0.862",
         "0.8960588999566912",
         "0.8213576816196904",
         "0.8570836785418393"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5096</td>\n",
       "      <td>0.510317</td>\n",
       "      <td>0.657801</td>\n",
       "      <td>0.574749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8828</td>\n",
       "      <td>0.890190</td>\n",
       "      <td>0.875347</td>\n",
       "      <td>0.882706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8620</td>\n",
       "      <td>0.896059</td>\n",
       "      <td>0.821358</td>\n",
       "      <td>0.857084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall  F1-Score\n",
       "0    0.5096   0.510317  0.657801  0.574749\n",
       "1    0.8828   0.890190  0.875347  0.882706\n",
       "2    0.8620   0.896059  0.821358  0.857084"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df[[\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to e:\\2_LEARNING_BKU\\2_File_2\\K22_HK242\\CO3085_NLP\\BT\\Lab09\\imdb_results.json\n"
     ]
    }
   ],
   "source": [
    "results_json_path = os.path.join(os.getcwd(), \"imdb_results.json\")\n",
    "\n",
    "with open(results_json_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(f\"Results saved to {results_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
