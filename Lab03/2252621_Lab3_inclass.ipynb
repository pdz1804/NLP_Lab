{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student: Nguyen Quang Phu\n",
    "\n",
    "Student ID: 2252621 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Language Model and Application for Spelling Error Correction**\n",
    "\n",
    "**Objective**: Develop a simple English syntax error correction program.\n",
    "\n",
    "a) Build a language model based on n-grams using the Laplace smoothing method for the following models:\n",
    "\n",
    "- 1-gram\n",
    "- 2-gram\n",
    "- 3-gram\n",
    "\n",
    "b) Calculate the probability of a sentence and compute the Perplexity of a sentence based on 1-gram, 2-gram, and 3-gram models.\n",
    "\n",
    "c) Analyze the results (Provide your own examples of spelling errors and calculate the probability of two similar sentences, where one has the correct word order and the other has an incorrect word order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in c:\\python312\\lib\\site-packages (5.2.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: matplotlib in c:\\python312\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: wordcloud in c:\\python312\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: nltk in c:\\python312\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\python312\\lib\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\python312\\lib\\site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\python312\\lib\\site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python312\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\python312\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\python312\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: click in c:\\python312\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python312\\lib\\site-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests[socks]->gdown) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests[socks]->gdown) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\python312\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install gdown matplotlib wordcloud nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import re\n",
    "import gdown\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "nltk.download('punkt')  # Download the Punkt tokenizer model\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable being used: c:\\Python312\\python.exe\n",
      "Python version: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]\n",
      "Operating System: Windows\n",
      "OS Version: 10.0.19045\n",
      "OS Release: 10\n",
      "Machine: AMD64\n",
      "Running in Visual Studio Code\n"
     ]
    }
   ],
   "source": [
    "# Python environment details\n",
    "print(\"Python executable being used:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "# Operating System details\n",
    "print(\"Operating System:\", platform.system())\n",
    "print(\"OS Version:\", platform.version())\n",
    "print(\"OS Release:\", platform.release())\n",
    "\n",
    "# Machine and architecture details\n",
    "print(\"Machine:\", platform.machine())\n",
    "\n",
    "# Visual Studio Code details (based on environment variable)\n",
    "vscode_info = os.environ.get('VSCODE_PID', None)\n",
    "if vscode_info:\n",
    "    print(\"Running in Visual Studio Code\")\n",
    "else:\n",
    "    print(\"Not running in Visual Studio Code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Clean a sentence by removing unwanted characters like '-', '(', ')', etc.\n",
    "    \"\"\"\n",
    "    cleaned = re.sub(r'[\\(\\)-]', '', sentence)  # Remove specific characters\n",
    "    cleaned = re.sub(r'[^\\w\\s.,!?]', '', cleaned)  # Keep only alphanumeric, spaces, and basic punctuation\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()  # Remove extra spaces and trim\n",
    "    \n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    \"\"\"\n",
    "    Load and preprocess text data from a file.\n",
    "    Split the data into sentences using nltk's sentence tokenizer.\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Clean each sentence\n",
    "    cleaned_sentences = [clean_sentence(sentence) for sentence in sentences]\n",
    "\n",
    "    # Debug: Print the first 10 sentences\n",
    "    print(\"First 10 sentences from the file:\")\n",
    "    for i, sentence in enumerate(cleaned_sentences[:10], start=1):\n",
    "        print(f\"{i}: {sentence}\")\n",
    "    \n",
    "    return cleaned_sentences  # Return the list of tokenized sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for building a specific n-gram model with given corpus and n value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_model(corpus, n):\n",
    "    \"\"\"\n",
    "    Build an n-gram model from a given corpus and given n.\n",
    "    \"\"\"\n",
    "    ngram_counts = defaultdict(int)\n",
    "    n_minus_1_counts = defaultdict(int)\n",
    "    vocabulary = set()\n",
    "\n",
    "    for sentence in corpus:\n",
    "        # Tokenize and add padding based on n\n",
    "        tokens = sentence.split()  # Tokenize the sentence\n",
    "        if n > 1:\n",
    "            tokens = ([\"<s>\"] * (n - 1)) + tokens + ([\"</s>\"] * (n - 1))\n",
    "        \n",
    "        # Update vocabulary\n",
    "        vocabulary.update(tokens)\n",
    "\n",
    "        # Generate n-grams and (n-1)-grams\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            ngram = tuple(tokens[i:i + n])\n",
    "            n_minus_1_gram = tuple(tokens[i:i + n - 1])\n",
    "            ngram_counts[ngram] += 1\n",
    "            n_minus_1_counts[n_minus_1_gram] += 1\n",
    "\n",
    "    return ngram_counts, n_minus_1_counts, len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for computing sentence probabilities with laplace smoothing\n",
    "\n",
    "1. **Understanding N-gram Probabilities**:\n",
    "   - An n-gram is a sequence of `n` tokens (words).\n",
    "   - The probability of an n-gram with Laplace smoothing is computed as:\n",
    "   - \n",
    "     $\n",
    "     P(w_i | w_{i-(n-1)}, \\ldots, w_{i-1}) = \\frac{\\text{Count}(w_{i-(n-1)}, \\ldots, w_i) + 1}{\\text{Count}(w_{i-(n-1)}, \\ldots, w_{i-1}) + V}\n",
    "     $\n",
    "\n",
    "     Where:\n",
    "     - $\\text{Count}(w_{i-(n-1)}, \\ldots, w_i)$: Count of the n-gram in the training data.\n",
    "     - $\\text{Count}(w_{i-(n-1)}, \\ldots, w_{i-1})$: Count of the (n-1)-gram prefix.\n",
    "     - $V$: Vocabulary size (total number of unique tokens in the training data).\n",
    "\n",
    "2. **Handling Zero Counts**:\n",
    "   - If the n-gram or its prefix does not appear in the training data, the smoothing process ensures a non-zero probability by adding 1 to the numerator and the vocabulary size $V$ to the denominator.\n",
    "\n",
    "3. **Sentence Probability**:\n",
    "   - A sentence's probability is the product of probabilities for all n-grams in the sentence:\n",
    "   - \n",
    "     $\n",
    "     P(\\text{sentence}) = \\prod_{i=1}^{N} P(w_i | w_{i-(n-1)}, \\ldots, w_{i-1})\n",
    "     $\n",
    "\n",
    "     Here, the sentence is tokenized with start (`<s>`) and end (`</s>`) markers to capture context at the boundaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_laplace_probability(ngram, ngram_counts, n_minus_1_counts, vocab_size):\n",
    "    \"\"\"\n",
    "    Compute the Laplace smoothed probability of an n-gram.\n",
    "    \"\"\"\n",
    "    ngram_count = ngram_counts[ngram]\n",
    "    n_minus_1_count = n_minus_1_counts[ngram[:-1]] if len(ngram) > 1 else sum(ngram_counts.values())\n",
    "    return (ngram_count + 1) / (n_minus_1_count + vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_probability(sentence, ngram_counts, n_minus_1_counts, vocab_size, n):\n",
    "    \"\"\"\n",
    "    Compute the probability of a sentence using an n-gram model with Laplace smoothing.\n",
    "    Debug statements added to trace computation.\n",
    "    \"\"\"\n",
    "    # Add padding based on n-gram size\n",
    "    if n > 1:\n",
    "        tokens = [\"<s>\"] * (n - 1) + sentence.split() + [\"</s>\"] * (n - 1)\n",
    "    else:\n",
    "        tokens = sentence.split()\n",
    "\n",
    "    print(f\"Tokens with padding for n={n}: {tokens}\")  \n",
    "\n",
    "    prob = 1.0  # Initialize probability\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        ngram = tuple(tokens[i:i + n])\n",
    "        ngram_prob = compute_laplace_probability(ngram, ngram_counts, n_minus_1_counts, vocab_size)\n",
    "        print(f\"N-gram: {ngram}, Probability: {ngram_prob}\")  \n",
    "\n",
    "        prob *= ngram_prob\n",
    "\n",
    "    print(f\"Final sentence probability: {prob}\")  \n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for computing perplexity with the used of laplace probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(sentence, ngram_counts, n_minus_1_counts, vocab_size, n):\n",
    "    \"\"\"\n",
    "    Compute the perplexity of a sentence using an n-gram model.\n",
    "    \"\"\"\n",
    "    # Add padding based on n-gram size\n",
    "    if n > 1:\n",
    "        tokens = [\"<s>\"] * (n - 1) + sentence.split() + [\"</s>\"] * (n - 1)\n",
    "    else:\n",
    "        tokens = sentence.split()\n",
    "        \n",
    "    prob = 0.0\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        ngram = tuple(tokens[i:i + n])\n",
    "        prob += math.log(compute_laplace_probability(ngram, ngram_counts, n_minus_1_counts, vocab_size))\n",
    "    prob = -prob / len(tokens)\n",
    "    return math.exp(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for building first 3 n-gram models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_models(filepath):\n",
    "    \"\"\"\n",
    "    Build n-gram models for 1-gram, 2-gram, and 3-gram.\n",
    "    \"\"\"\n",
    "    corpus = load_data(filepath)\n",
    "    ngram_models = {}\n",
    "    \n",
    "    for n in range(1, 4): \n",
    "        ngram_counts, n_minus_1_counts, vocab_size = build_ngram_model(corpus, n)\n",
    "        ngram_models[n] = (ngram_counts, n_minus_1_counts, vocab_size)\n",
    "    \n",
    "    return ngram_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for calculating the probability and the perplexity of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentence(sentence, ngram_models):\n",
    "    \"\"\"\n",
    "    Analyze a sentence by computing its probability and perplexity for 1-gram, 2-gram, and 3-gram models.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for n, (ngram_counts, n_minus_1_counts, vocab_size) in ngram_models.items():\n",
    "        prob = sentence_probability(sentence, ngram_counts, n_minus_1_counts, vocab_size, n)\n",
    "        perplexity = compute_perplexity(sentence, ngram_counts, n_minus_1_counts, vocab_size, n)\n",
    "        results[n] = {\"probability\": prob, \"perplexity\": perplexity}\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for comparing 2 sentences by analyzing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sentences(correct_sentence, incorrect_sentence, ngram_models):\n",
    "    \"\"\"\n",
    "    Compare probabilities and perplexities of two sentences: one correct and one incorrect.\n",
    "    \"\"\"\n",
    "    correct_results = analyze_sentence(correct_sentence, ngram_models)\n",
    "    print(\"\\n\\n\")\n",
    "    incorrect_results = analyze_sentence(incorrect_sentence, ngram_models)\n",
    "\n",
    "    comparison = {}\n",
    "    for n in correct_results.keys():\n",
    "        # Extract probabilities and perplexities for both sentences\n",
    "        correct_prob = correct_results[n][\"probability\"]\n",
    "        incorrect_prob = incorrect_results[n][\"probability\"]\n",
    "        correct_perplexity = correct_results[n][\"perplexity\"]\n",
    "        incorrect_perplexity = incorrect_results[n][\"perplexity\"]\n",
    "\n",
    "        if correct_perplexity < incorrect_perplexity:\n",
    "            higher_sentence = \"Correct Sentence\"\n",
    "        elif incorrect_perplexity < correct_perplexity:\n",
    "            higher_sentence = \"Incorrect Sentence\"\n",
    "        else:\n",
    "            higher_sentence = \"Both sentences have equal probability\"\n",
    "\n",
    "        # Store comparison results\n",
    "        comparison[n] = {\n",
    "            \"correct\": {\n",
    "                \"probability\": correct_prob,\n",
    "                \"perplexity\": correct_perplexity,\n",
    "            },\n",
    "            \"incorrect\": {\n",
    "                \"probability\": incorrect_prob,\n",
    "                \"perplexity\": incorrect_perplexity,\n",
    "            },\n",
    "            \"higher_probability\": higher_sentence,\n",
    "            \"probability_difference\": abs(correct_prob - incorrect_prob),\n",
    "            \"perplexity_difference\": abs(correct_perplexity - incorrect_perplexity),\n",
    "        }\n",
    "\n",
    "    return comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Main functions for the Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: Develop a simple English syntax error correction program.\n",
    "\n",
    "a) Build a language model based on n-grams using the Laplace smoothing method for the following models:\n",
    "\n",
    "- 1-gram\n",
    "- 2-gram\n",
    "- 3-gram\n",
    "\n",
    "b) Calculate the probability of a sentence and compute the Perplexity of a sentence based on 1-gram, 2-gram, and 3-gram models.\n",
    "\n",
    "c) Analyze the results (Provide your own examples of spelling errors and calculate the probability of two similar sentences, where one has the correct word order and the other has an incorrect word order)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the tedtalk from public link google drive to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted File ID: 1ZFXJVav0rZ0V2TadMuY0TxWuwxkhN-nq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ZFXJVav0rZ0V2TadMuY0TxWuwxkhN-nq\n",
      "To: e:\\2_LEARNING_BKU\\2_File_2\\K22_HK242\\CO3085_NLP\\BT\\Lab03\\tedtalk.txt\n",
      "100%|██████████| 40.3M/40.3M [00:03<00:00, 10.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download tedtalk\n",
    "url = \"https://drive.google.com/file/d/1ZFXJVav0rZ0V2TadMuY0TxWuwxkhN-nq/view?usp=sharing\"\n",
    "\n",
    "def download_from_google_drive(url, output_filename=None):\n",
    "    # Extract file ID using regex\n",
    "    match = re.search(r\"/d/([^/]+)\", url)\n",
    "    if not match:\n",
    "        print(\"Error: Could not extract file ID from the URL.\")\n",
    "        return\n",
    "    \n",
    "    file_id = match.group(1)\n",
    "    print(f\"Extracted File ID: {file_id}\")\n",
    "\n",
    "    download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "    if output_filename:\n",
    "        gdown.download(download_url, output_filename, quiet=False)\n",
    "    else:\n",
    "        gdown.download(download_url, quiet=False)\n",
    "\n",
    "url = \"https://drive.google.com/file/d/1ZFXJVav0rZ0V2TadMuY0TxWuwxkhN-nq/view?usp=sharing\"\n",
    "download_from_google_drive(url, \"tedtalk.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Build n-gram models using Laplace smoothing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building n-gram models...\n",
      "First 10 sentences from the file:\n",
      "1: Thank you so much, Chris.\n",
      "2: And its truly a great honor to have the opportunity to come to this stage twice Im extremely grateful.\n",
      "3: I have been blown away by this conference, and I want to thank all of you for the many nice comments about what I had to say the other night.\n",
      "4: And I say that sincerely, partly because Mock sob I need that.\n",
      "5: Laughter Put yourselves in my position.\n",
      "6: Laughter I flew on Air Force Two for eight years.\n",
      "7: Laughter Now I have to take off my shoes or boots to get on an airplane!\n",
      "8: Laughter Applause Ill tell you one quick story to illustrate what thats been like for me.\n",
      "9: Laughter Its a true story every bit of this is true.\n",
      "10: Soon after Tipper and I left the Mock sob White House Laughter we were driving from our home in Nashville to a little farm we have 50 miles east of Nashville.\n"
     ]
    }
   ],
   "source": [
    "# Path \n",
    "dataset_path = os.path.join(os.getcwd(), \"tedtalk.txt\")\n",
    "\n",
    "# n-gram models\n",
    "print(\"Building n-gram models...\")\n",
    "ngram_models = build_ngram_models(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N-gram Counts for Each Model:\n",
      "\n",
      "1-gram Model Counts:\n",
      "('Thank',): 4422\n",
      "('you',): 75911\n",
      "('so',): 22408\n",
      "('much,',): 374\n",
      "('Chris.',): 56\n",
      "('And',): 62910\n",
      "('its',): 25849\n",
      "('truly',): 652\n",
      "('a',): 166604\n",
      "('great',): 3565\n",
      "('honor',): 191\n",
      "('to',): 207468\n",
      "('have',): 42789\n",
      "('the',): 315455\n",
      "('opportunity',): 873\n",
      "('come',): 5564\n",
      "('this',): 55079\n",
      "('stage',): 492\n",
      "('twice',): 339\n",
      "('Im',): 13440\n",
      "('extremely',): 636\n",
      "('grateful.',): 22\n",
      "('I',): 107400\n",
      "('been',): 11132\n",
      "('blown',): 84\n",
      "('away',): 2019\n",
      "('by',): 19069\n",
      "('conference,',): 72\n",
      "('and',): 175784\n",
      "('want',): 10520\n",
      "... (Total unique 1-grams: 163312)\n",
      "\n",
      "2-gram Model Counts:\n",
      "('<s>', 'Thank'): 3234\n",
      "('Thank', 'you'): 1203\n",
      "('you', 'so'): 321\n",
      "('so', 'much,'): 107\n",
      "('much,', 'Chris.'): 4\n",
      "('Chris.', '</s>'): 56\n",
      "('<s>', 'And'): 59698\n",
      "('And', 'its'): 1442\n",
      "('its', 'truly'): 10\n",
      "('truly', 'a'): 19\n",
      "('a', 'great'): 1174\n",
      "('great', 'honor'): 16\n",
      "('honor', 'to'): 26\n",
      "('to', 'have'): 3164\n",
      "('have', 'the'): 2253\n",
      "('the', 'opportunity'): 302\n",
      "('opportunity', 'to'): 501\n",
      "('to', 'come'): 1179\n",
      "('come', 'to'): 976\n",
      "('to', 'this'): 1271\n",
      "('this', 'stage'): 53\n",
      "('stage', 'twice'): 1\n",
      "('twice', 'Im'): 1\n",
      "('Im', 'extremely'): 12\n",
      "('extremely', 'grateful.'): 1\n",
      "('grateful.', '</s>'): 22\n",
      "('<s>', 'I'): 23683\n",
      "('I', 'have'): 3509\n",
      "('have', 'been'): 2649\n",
      "('been', 'blown'): 4\n",
      "... (Total unique 2-grams: 1752197)\n",
      "\n",
      "3-gram Model Counts:\n",
      "('<s>', '<s>', 'Thank'): 3234\n",
      "('<s>', 'Thank', 'you'): 947\n",
      "('Thank', 'you', 'so'): 207\n",
      "('you', 'so', 'much,'): 22\n",
      "('so', 'much,', 'Chris.'): 3\n",
      "('much,', 'Chris.', '</s>'): 4\n",
      "('Chris.', '</s>', '</s>'): 56\n",
      "('<s>', '<s>', 'And'): 59698\n",
      "('<s>', 'And', 'its'): 1386\n",
      "('And', 'its', 'truly'): 3\n",
      "('its', 'truly', 'a'): 2\n",
      "('truly', 'a', 'great'): 1\n",
      "('a', 'great', 'honor'): 8\n",
      "('great', 'honor', 'to'): 8\n",
      "('honor', 'to', 'have'): 4\n",
      "('to', 'have', 'the'): 185\n",
      "('have', 'the', 'opportunity'): 54\n",
      "('the', 'opportunity', 'to'): 230\n",
      "('opportunity', 'to', 'come'): 8\n",
      "('to', 'come', 'to'): 170\n",
      "('come', 'to', 'this'): 31\n",
      "('to', 'this', 'stage'): 3\n",
      "('this', 'stage', 'twice'): 1\n",
      "('stage', 'twice', 'Im'): 1\n",
      "('twice', 'Im', 'extremely'): 1\n",
      "('Im', 'extremely', 'grateful.'): 1\n",
      "('extremely', 'grateful.', '</s>'): 1\n",
      "('grateful.', '</s>', '</s>'): 22\n",
      "('<s>', '<s>', 'I'): 23683\n",
      "('<s>', 'I', 'have'): 811\n",
      "... (Total unique 3-grams: 4279777)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nN-gram Counts for Each Model:\")\n",
    "for n, (ngram_counts, _, _) in ngram_models.items():\n",
    "    print(f\"\\n{n}-gram Model Counts:\")\n",
    "    \n",
    "    for ngram, count in list(ngram_counts.items())[:30]: \n",
    "        print(f\"{ngram}: {count}\")\n",
    "    \n",
    "    print(f\"... (Total unique {n}-grams: {len(ngram_counts)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Calculate the probability and perplexity of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentence: That man over there is so handsome\n",
      "Tokens with padding for n=1: ['That', 'man', 'over', 'there', 'is', 'so', 'handsome']\n",
      "N-gram: ('That',), Probability: 0.0005227573613579725\n",
      "N-gram: ('man',), Probability: 0.00020762769513042024\n",
      "N-gram: ('over',), Probability: 0.001083625332545805\n",
      "N-gram: ('there',), Probability: 0.0019332597165663407\n",
      "N-gram: ('is',), Probability: 0.012566802844936534\n",
      "N-gram: ('so',), Probability: 0.00306100593432736\n",
      "N-gram: ('handsome',), Probability: 3.1417348605260957e-06\n",
      "Final sentence probability: 2.747978276158006e-23\n",
      "Tokens with padding for n=2: ['<s>', 'That', 'man', 'over', 'there', 'is', 'so', 'handsome', '</s>']\n",
      "N-gram: ('<s>', 'That'), Probability: 0.005737858677873619\n",
      "N-gram: ('That', 'man'), Probability: 1.1966016513102789e-05\n",
      "N-gram: ('man', 'over'), Probability: 3.033373171634321e-05\n",
      "N-gram: ('over', 'there'), Probability: 0.00033285449003188393\n",
      "N-gram: ('there', 'is'), Probability: 0.013895619442597455\n",
      "N-gram: ('is', 'so'), Probability: 0.0029689164629942972\n",
      "N-gram: ('so', 'handsome'), Probability: 5.384391725266797e-06\n",
      "N-gram: ('handsome', '</s>'), Probability: 6.122349022873096e-06\n",
      "Final sentence probability: 9.427799293979578e-31\n",
      "Tokens with padding for n=3: ['<s>', '<s>', 'That', 'man', 'over', 'there', 'is', 'so', 'handsome', '</s>', '</s>']\n",
      "N-gram: ('<s>', '<s>', 'That'), Probability: 0.005737858677873619\n",
      "N-gram: ('<s>', 'That', 'man'), Probability: 5.995203836930455e-06\n",
      "N-gram: ('That', 'man', 'over'), Probability: 6.123136270397698e-06\n",
      "N-gram: ('man', 'over', 'there'), Probability: 6.123023794070464e-06\n",
      "N-gram: ('over', 'there', 'is'), Probability: 5.508967374670992e-05\n",
      "N-gram: ('there', 'is', 'so'), Probability: 0.00013873892350659613\n",
      "N-gram: ('is', 'so', 'handsome'), Probability: 6.094922320215029e-06\n",
      "N-gram: ('so', 'handsome', '</s>'), Probability: 6.123173763425059e-06\n",
      "N-gram: ('handsome', '</s>', '</s>'), Probability: 6.123173763425059e-06\n",
      "Final sentence probability: 2.2525971837323073e-42\n",
      "\n",
      "Sentence Analysis:\n",
      "\n",
      "1-gram Model:\n",
      "Probability: 2.747978276158006e-23\n",
      "Perplexity: 1671.0833061279054\n",
      "\n",
      "2-gram Model:\n",
      "Probability: 9.427799293979578e-31\n",
      "Perplexity: 2168.5859024393185\n",
      "\n",
      "3-gram Model:\n",
      "Probability: 2.2525971837323073e-42\n",
      "Perplexity: 6111.104053163396\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = \"That man over there is so handsome\"\n",
    "\n",
    "print(\"Sample sentence:\", sample_sentence)\n",
    "\n",
    "result = analyze_sentence(sample_sentence, ngram_models)\n",
    "print(\"\\nSentence Analysis:\")\n",
    "for n, values in result.items():\n",
    "    print(f\"\\n{n}-gram Model:\")\n",
    "    print(f\"Probability: {values['probability']}\")\n",
    "    print(f\"Perplexity: {values['perplexity']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Analyze the results (Provide your own examples of spelling errors and calculate the probability of two similar sentences, where one has the correct word order and the other has an incorrect word order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens with padding for n=1: ['the', 'cat', 'sat', 'on', 'the', 'mat']\n",
      "N-gram: ('the',), Probability: 0.04309039618096174\n",
      "N-gram: ('cat',), Probability: 2.1718949687984748e-05\n",
      "N-gram: ('sat',), Probability: 6.228830853912608e-05\n",
      "N-gram: ('on',), Probability: 0.005241643121868168\n",
      "N-gram: ('the',), Probability: 0.04309039618096174\n",
      "N-gram: ('mat',), Probability: 1.0927773427916854e-06\n",
      "Final sentence probability: 1.4388166724576847e-20\n",
      "Tokens with padding for n=2: ['<s>', 'the', 'cat', 'sat', 'on', 'the', 'mat', '</s>']\n",
      "N-gram: ('<s>', 'the'), Probability: 5.430150168334655e-05\n",
      "N-gram: ('the', 'cat'), Probability: 5.848331867769217e-05\n",
      "N-gram: ('cat', 'sat'), Probability: 6.1172555544680435e-06\n",
      "N-gram: ('sat', 'on'), Probability: 0.00021371566047298328\n",
      "N-gram: ('on', 'the'), Probability: 0.056389635373798874\n",
      "N-gram: ('the', 'mat'), Probability: 4.17737990554944e-06\n",
      "N-gram: ('mat', '</s>'), Probability: 6.122911321875326e-06\n",
      "Final sentence probability: 5.988224163869548e-30\n",
      "Tokens with padding for n=3: ['<s>', '<s>', 'the', 'cat', 'sat', 'on', 'the', 'mat', '</s>', '</s>']\n",
      "N-gram: ('<s>', '<s>', 'the'), Probability: 5.430150168334655e-05\n",
      "N-gram: ('<s>', 'the', 'cat'), Probability: 6.121974214244609e-06\n",
      "N-gram: ('the', 'cat', 'sat'), Probability: 6.122161612822255e-06\n",
      "N-gram: ('cat', 'sat', 'on'), Probability: 6.123173763425059e-06\n",
      "N-gram: ('sat', 'on', 'the'), Probability: 9.182848887038715e-05\n",
      "N-gram: ('on', 'the', 'mat'), Probability: 5.724557205500154e-06\n",
      "N-gram: ('the', 'mat', '</s>'), Probability: 6.123136270397698e-06\n",
      "N-gram: ('mat', '</s>', '</s>'), Probability: 6.123173763425059e-06\n",
      "Final sentence probability: 2.4561481326231865e-40\n",
      "\n",
      "\n",
      "\n",
      "Tokens with padding for n=1: ['cat', 'the', 'the', 'on', 'mat', 'sat']\n",
      "N-gram: ('cat',), Probability: 2.1718949687984748e-05\n",
      "N-gram: ('the',), Probability: 0.04309039618096174\n",
      "N-gram: ('the',), Probability: 0.04309039618096174\n",
      "N-gram: ('on',), Probability: 0.005241643121868168\n",
      "N-gram: ('mat',), Probability: 1.0927773427916854e-06\n",
      "N-gram: ('sat',), Probability: 6.228830853912608e-05\n",
      "Final sentence probability: 1.438816672457685e-20\n",
      "Tokens with padding for n=2: ['<s>', 'cat', 'the', 'the', 'on', 'mat', 'sat', '</s>']\n",
      "N-gram: ('<s>', 'cat'), Probability: 3.291000102021003e-06\n",
      "N-gram: ('cat', 'the'), Probability: 6.1172555544680435e-06\n",
      "N-gram: ('the', 'the'), Probability: 5.012855886659328e-05\n",
      "N-gram: ('the', 'on'), Probability: 2.08868995277472e-06\n",
      "N-gram: ('on', 'mat'), Probability: 4.958202354154478e-06\n",
      "N-gram: ('mat', 'sat'), Probability: 6.122911321875326e-06\n",
      "N-gram: ('sat', '</s>'), Probability: 6.106161727799523e-06\n",
      "Final sentence probability: 3.907457260193631e-37\n",
      "Tokens with padding for n=3: ['<s>', '<s>', 'cat', 'the', 'the', 'on', 'mat', 'sat', '</s>', '</s>']\n",
      "N-gram: ('<s>', '<s>', 'cat'), Probability: 3.291000102021003e-06\n",
      "N-gram: ('<s>', 'cat', 'the'), Probability: 6.123136270397698e-06\n",
      "N-gram: ('cat', 'the', 'the'), Probability: 6.123173763425059e-06\n",
      "N-gram: ('the', 'the', 'on'), Probability: 6.122311539945021e-06\n",
      "N-gram: ('the', 'on', 'mat'), Probability: 6.123173763425059e-06\n",
      "N-gram: ('on', 'mat', 'sat'), Probability: 6.123173763425059e-06\n",
      "N-gram: ('mat', 'sat', '</s>'), Probability: 6.123173763425059e-06\n",
      "N-gram: ('sat', '</s>', '</s>'), Probability: 6.123173763425059e-06\n",
      "Final sentence probability: 1.0619404555746645e-42\n"
     ]
    }
   ],
   "source": [
    "# Example sentences for comparison\n",
    "correct_sentence_example = \"the cat sat on the mat\"  \n",
    "incorrect_sentence = \"cat the the on mat sat\"\n",
    "\n",
    "# Compare probabilities and perplexities\n",
    "comparison = compare_sentences(correct_sentence_example, incorrect_sentence, ngram_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Correct vs Incorrect Sentences:\n",
      "\n",
      "1-gram Model:\n",
      "Correct Sentence - Probability: 1.438817e-20, Perplexity: 2027.6784695597984864\n",
      "Incorrect Sentence - Probability: 1.438817e-20, Perplexity: 2027.6784695597984864\n",
      "Higher Probability (Lower Perplexity): Both sentences have equal probability\n",
      "Perplexity Difference: 0.0000000000000000\n",
      "\n",
      "2-gram Model:\n",
      "Correct Sentence - Probability: 5.988224e-30, Perplexity: 4496.1184463538020282\n",
      "Incorrect Sentence - Probability: 3.907457e-37, Perplexity: 35564.2144581818647566\n",
      "Higher Probability (Lower Perplexity): Correct Sentence\n",
      "Perplexity Difference: 31068.0960118280636379\n",
      "\n",
      "3-gram Model:\n",
      "Correct Sentence - Probability: 2.456148e-40, Perplexity: 9140.5966350087601313\n",
      "Incorrect Sentence - Probability: 1.061940e-42, Perplexity: 15753.9688859854304610\n",
      "Higher Probability (Lower Perplexity): Correct Sentence\n",
      "Perplexity Difference: 6613.3722509766703297\n"
     ]
    }
   ],
   "source": [
    "# Display comparison results\n",
    "print(\"\\nComparison of Correct vs Incorrect Sentences:\")\n",
    "for n, results in comparison.items():\n",
    "    print(f\"\\n{n}-gram Model:\")\n",
    "    print(f\"Correct Sentence - Probability: {results['correct']['probability']:.6e}, Perplexity: {results['correct']['perplexity']:.16f}\")\n",
    "    print(f\"Incorrect Sentence - Probability: {results['incorrect']['probability']:.6e}, Perplexity: {results['incorrect']['perplexity']:.16f}\")\n",
    "    print(f\"Higher Probability (Lower Perplexity): {results['higher_probability']}\")\n",
    "    print(f\"Perplexity Difference: {results['perplexity_difference']:.16f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
