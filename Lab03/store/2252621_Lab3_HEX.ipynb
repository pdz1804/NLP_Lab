{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Home Exercise:**\n",
    "\n",
    "a) Improve the model by using interpolation smoothing with the \"Stupid Backoff\" method (Brants et al., 2007).\n",
    "\n",
    "b) Compare with the results from In Class Exercise.\n",
    "\n",
    "c) Use the newly built model to generate the next words for a given word sequence.\n",
    "\n",
    "d) Combine with a function that calculates the distance between words to predict the correct word for a misspelled word position. (from difflib import get_close_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdownNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting beautifulsoup4 (from gdown)\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gdown) (3.15.4)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gdown) (4.66.5)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4->gdown) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests[socks]->gdown) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests[socks]->gdown) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests[socks]->gdown) (2024.8.30)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Using cached gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, PySocks, beautifulsoup4, gdown\n",
      "Successfully installed PySocks-1.7.1 beautifulsoup4-4.13.3 gdown-5.2.0 soupsieve-2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install gdown matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable being used: c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n",
      "Python version: 3.11.5 (tags/v3.11.5:cce6ba9, Aug 24 2023, 14:38:34) [MSC v.1936 64 bit (AMD64)]\n",
      "Operating System: Windows\n",
      "OS Version: 10.0.19045\n",
      "OS Release: 10\n",
      "Machine: AMD64\n",
      "Running in Visual Studio Code\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# import platform\n",
    "\n",
    "# # Python environment details\n",
    "# print(\"Python executable being used:\", sys.executable)\n",
    "# print(\"Python version:\", sys.version)\n",
    "\n",
    "# # Operating System details\n",
    "# print(\"Operating System:\", platform.system())\n",
    "# print(\"OS Version:\", platform.version())\n",
    "# print(\"OS Release:\", platform.release())\n",
    "\n",
    "# # Machine and architecture details\n",
    "# print(\"Machine:\", platform.machine())\n",
    "\n",
    "# # Visual Studio Code details (based on environment variable)\n",
    "# vscode_info = os.environ.get('VSCODE_PID', None)\n",
    "# if vscode_info:\n",
    "#     print(\"Running in Visual Studio Code\")\n",
    "# else:\n",
    "#     print(\"Not running in Visual Studio Code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import gdown\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from difflib import get_close_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    \"\"\"\n",
    "    Load and preprocess text data from a file.\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        sentences = file.readlines()\n",
    "    \n",
    "    # Add <s> and </s> to each sentence and tokenize\n",
    "    tokens = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip().lower()\n",
    "        if sentence:  \n",
    "            tokens.extend([\"<s>\"] + sentence.split() + [\"</s>\"])\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build n-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_model(corpus, n):\n",
    "    \"\"\"\n",
    "    Build an n-gram model from a given corpus.\n",
    "    \"\"\"\n",
    "    ngram_counts = defaultdict(int)\n",
    "    n_minus_1_counts = defaultdict(int)\n",
    "    vocabulary = set(corpus)\n",
    "\n",
    "    for i in range(len(corpus) - n + 1):\n",
    "        ngram = tuple(corpus[i:i + n])\n",
    "        n_minus_1_gram = tuple(corpus[i:i + n - 1])\n",
    "        ngram_counts[ngram] += 1\n",
    "        n_minus_1_counts[n_minus_1_gram] += 1\n",
    "\n",
    "    return ngram_counts, n_minus_1_counts, len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Sentence Probabilities with laplace smoothed probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_laplace_probability(ngram, ngram_counts, n_minus_1_counts, vocab_size):\n",
    "    \"\"\"\n",
    "    Compute the Laplace smoothed probability of an n-gram.\n",
    "    \"\"\"\n",
    "    ngram_count = ngram_counts[ngram]\n",
    "    n_minus_1_count = n_minus_1_counts[ngram[:-1]] if len(ngram) > 1 else sum(ngram_counts.values())\n",
    "    return (ngram_count + 1) / (n_minus_1_count + vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_probability(sentence, ngram_counts, n_minus_1_counts, vocab_size, n):\n",
    "    \"\"\"\n",
    "    Compute the probability of a sentence using an n-gram model with laplace smoothing.\n",
    "    \"\"\"\n",
    "    tokens = [\"<s>\"] + sentence.split() + [\"</s>\"]\n",
    "    prob = 1.0\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        ngram = tuple(tokens[i:i + n])\n",
    "        prob *= compute_laplace_probability(ngram, ngram_counts, n_minus_1_counts, vocab_size)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Sentence Probabilities with Stupid Backoff method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stupid_backoff_probability(ngram, ngram_models, alpha=0.4, laplace_smoothing=True):\n",
    "    \"\"\"\n",
    "    Compute probability using Stupid Backoff method combined with optional Laplace smoothing.\n",
    "\n",
    "    Returns:\n",
    "        float: The probability or relative score of the n-gram.\n",
    "    \"\"\"\n",
    "    for n in range(len(ngram), 0, -1):  # Start with highest n-gram and backoff to lower-order\n",
    "        ngram_model = ngram_models.get(n)\n",
    "        if ngram_model:\n",
    "            ngram_counts, n_minus_1_counts, vocab_size = ngram_model\n",
    "            \n",
    "            if ngram in ngram_counts:\n",
    "                ngram_count = ngram_counts[ngram]\n",
    "                n_minus_1_count = n_minus_1_counts[ngram[:-1]] if len(ngram) > 1 else sum(ngram_counts.values())\n",
    "\n",
    "                if laplace_smoothing:\n",
    "                    # Laplace smoothing ensures non-zero probability\n",
    "                    return (ngram_count + 1) / (n_minus_1_count + vocab_size)\n",
    "                else:\n",
    "                    # Stupid Backoff with relative frequency\n",
    "                    return ngram_count / n_minus_1_count if n_minus_1_count > 0 else 0\n",
    "\n",
    "    # Backoff to unigram model if higher-order n-grams are not found\n",
    "    unigram_model = ngram_models.get(1)\n",
    "    if unigram_model:\n",
    "        unigram_counts, _, vocab_size = unigram_model\n",
    "        unigram_count = unigram_counts.get((ngram[-1],), 0)  # Frequency of the unigram\n",
    "        total_count = sum(unigram_counts.values())  # Total number of tokens\n",
    "\n",
    "        if laplace_smoothing:\n",
    "            # Laplace smoothing for unigrams\n",
    "            return (unigram_count + 1) / (total_count + vocab_size)\n",
    "        else:\n",
    "            # Stupid Backoff with relative frequency\n",
    "            return unigram_count / total_count if total_count > 0 else 0\n",
    "\n",
    "    # Fallback: Return the alpha (backoff factor) for unseen cases\n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_probability_with_backoff(sentence, ngram_models, alpha=0.4):\n",
    "    \"\"\"\n",
    "    Compute the probability of a sentence using Stupid Backoff smoothing.\n",
    "    \"\"\"\n",
    "    tokens = [\"<s>\"] + sentence.split() + [\"</s>\"]\n",
    "    prob = 1.0\n",
    "    for i in range(len(tokens)):\n",
    "        for n in range(3, 0, -1):  # Try 3-gram, 2-gram, then 1-gram\n",
    "            ngram = tuple(tokens[i:i + n])\n",
    "            if len(ngram) == n:\n",
    "                prob *= compute_stupid_backoff_probability(ngram, ngram_models, alpha)\n",
    "                break\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare sentences by using soothing with laplace and with stupid backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sentences_with_smoothing(sentence1, sentence2, ngram_models, alpha=0.4):\n",
    "    \"\"\"\n",
    "    Compare probabilities and perplexities of two sentences using both Laplace and Stupid Backoff.\n",
    "    \"\"\"\n",
    "    results = {\"Laplace\": {}, \"Stupid Backoff\": {}}\n",
    "\n",
    "    # Compare using Laplace smoothing\n",
    "    for n in range(1, 4):\n",
    "        ngram_model = ngram_models[n]\n",
    "        \n",
    "        sentence1_prob_laplace = sentence_probability(sentence1, *ngram_model, n)\n",
    "        sentence2_prob_laplace = sentence_probability(sentence2, *ngram_model, n)\n",
    "        \n",
    "        if sentence1_prob_laplace > sentence2_prob_laplace:\n",
    "            higher_sentence = \"Sentence 1 (Correct)\"\n",
    "        elif sentence2_prob_laplace > sentence1_prob_laplace:\n",
    "            higher_sentence = \"Sentence 2 (Incorrect)\"\n",
    "        else:\n",
    "            higher_sentence = \"Both sentences have equal probability\"\n",
    "        \n",
    "        results[\"Laplace\"][f\"{n}-gram\"] = {\n",
    "            \"sentence1\": sentence1_prob_laplace,\n",
    "            \"sentence2\": sentence2_prob_laplace,\n",
    "            \"higher_probability\": higher_sentence,\n",
    "            \"probability_difference\": abs(sentence1_prob_laplace - sentence2_prob_laplace),\n",
    "        }\n",
    "\n",
    "    # Compare using Stupid Backoff smoothing\n",
    "    sentence1_prob_backoff = sentence_probability_with_backoff(sentence1, ngram_models, alpha)\n",
    "    sentence2_prob_backoff = sentence_probability_with_backoff(sentence2, ngram_models, alpha)\n",
    "\n",
    "    if sentence1_prob_backoff > sentence2_prob_backoff:\n",
    "        higher_sentence = \"Sentence 1 (Correct)\"\n",
    "    elif sentence2_prob_backoff > sentence1_prob_backoff:\n",
    "        higher_sentence = \"Sentence 2 (Incorrect)\"\n",
    "    else:\n",
    "        higher_sentence = \"Both sentences have equal probability\"\n",
    "\n",
    "    results[\"Stupid Backoff\"] = {\n",
    "        \"sentence1\": sentence1_prob_backoff,\n",
    "        \"sentence2\": sentence2_prob_backoff,\n",
    "        \"higher_probability\": higher_sentence,\n",
    "        \"probability_difference\": abs(sentence1_prob_backoff - sentence2_prob_backoff),\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for predicting the next top-k tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Stupid Backoff method scores n-grams using relative frequencies but does **not normalize** probabilities to sum to 1. It uses a backoff mechanism to handle cases where an n-gram does not exist in the training data.\n",
    "\n",
    "### Backoff Strategy\n",
    "- Start with the highest-order n-gram (e.g., trigram).\n",
    "- If the n-gram is **not found**, back off to the next lower-order n-gram (e.g., bigram).\n",
    "- Continue until the unigram model is reached.\n",
    "- If no match is found, return the **backoff factor** ($\\alpha$).\n",
    "\n",
    "### Backoff Factor ($\\alpha$)\n",
    "- $\\alpha$ is a constant multiplier used for scoring lower-order n-grams.\n",
    "- It is typically set to $0.4$, as per the original implementation of Stupid Backoff.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Combined Stupid Backoff with Optional Laplace Smoothing\n",
    "\n",
    "The code combines **Stupid Backoff** with an option for **Laplace Smoothing** to handle zero probabilities.\n",
    "\n",
    "### Steps:\n",
    "1. **Start with the Highest n-gram**:\n",
    "   - Look for the n-gram in the training data.\n",
    "   - If found:\n",
    "     - Use Laplace Smoothing:  \n",
    "       $\n",
    "       P(w_i|w_{i-(n-1)}, ..., w_{i-1}) = \\frac{\\text{Count}(w_i, w_{i-(n-1)}, ..., w_{i-1}) + 1}{\\text{Count}(w_{i-(n-1)}, ..., w_{i-1}) + V}\n",
    "       $\n",
    "       Where $V$ is the vocabulary size.\n",
    "     - Otherwise, return the relative frequency:\n",
    "       $\n",
    "       P(w_i|w_{i-(n-1)}, ..., w_{i-1}) = \\frac{\\text{Count}(w_i, w_{i-(n-1)}, ..., w_{i-1})}{\\text{Count}(w_{i-(n-1)}, ..., w_{i-1})}\n",
    "       $\n",
    "\n",
    "2. **Backoff to Lower-Order n-grams**:\n",
    "   - If the n-gram is not found, reduce the order (e.g., backoff from trigram to bigram).\n",
    "   - Repeat the probability calculation for the lower-order n-gram.\n",
    "\n",
    "3. **Fallback to Unigram**:\n",
    "   - If no n-grams match, compute the unigram probability:\n",
    "     - With Laplace Smoothing:\n",
    "       $\n",
    "       P(w_i) = \\frac{\\text{Count}(w_i) + 1}{\\text{Total Words} + V}\n",
    "       $\n",
    "     - Without Laplace Smoothing:\n",
    "       $\n",
    "       P(w_i) = \\frac{\\text{Count}(w_i)}{\\text{Total Words}}\n",
    "       $\n",
    "\n",
    "4. **Return Backoff Factor**:\n",
    "   - If the word is entirely unseen, return $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(sequence, ngram_models, alpha=0.4, top_k=5):\n",
    "    \"\"\"\n",
    "    Predict the next word for a given sequence using the Stupid Backoff method.\n",
    "    Returns:\n",
    "        list: Top-k predicted words and their scores.\n",
    "    \"\"\"\n",
    "    sequence_tokens = sequence.split()\n",
    "    candidates = defaultdict(float)\n",
    "\n",
    "    print(f\"\\nInput sequence: '{sequence}'\")\n",
    "    print(f\"Tokens: {sequence_tokens}\")\n",
    "\n",
    "    # Iterate over all n-grams (from highest available to unigram)\n",
    "    for n in range(3, 1, -1):  # 3-gram to 1-gram\n",
    "        ngram_model = ngram_models.get(n)\n",
    "        if not ngram_model:\n",
    "            continue\n",
    "        \n",
    "        ngram_counts, _, _ = ngram_model\n",
    "        prefix = tuple(sequence_tokens[-(n - 1):]) if n > 1 else tuple()\n",
    "\n",
    "        print(f\"\\nSearching for {n}-grams with prefix: {prefix}\")\n",
    "\n",
    "        for ngram, count in ngram_counts.items():\n",
    "            if ngram[:-1] == prefix:  # Match the prefix\n",
    "                word = ngram[-1]\n",
    "                score = compute_stupid_backoff_probability(ngram, ngram_models, alpha)\n",
    "                candidates[word] += score\n",
    "                print(f\"Match found: {ngram}, Count: {count}, Score: {score:.6f}\")\n",
    "\n",
    "    # Sort candidates by their scores\n",
    "    sorted_candidates = sorted(candidates.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"\\nTop candidate words and scores:\")\n",
    "    for word, score in sorted_candidates[:top_k]:\n",
    "        print(f\"Word: {word}, Score: {score:.6f}\")\n",
    "\n",
    "    return sorted_candidates[:top_k]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for correcting the misspelled word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_misspelled_word(word, vocabulary, ngram_models, context, alpha=0.4, top_k=5):\n",
    "    \"\"\"\n",
    "    Predict the correct word for a misspelled word using Stupid Backoff and semantic similarity.\n",
    "    Returns:\n",
    "        str: The corrected word.\n",
    "    \"\"\"\n",
    "    # Step 1: Use difflib to get similar words\n",
    "    similar_words = get_close_matches(word, vocabulary, n=top_k)\n",
    "\n",
    "    if not similar_words:\n",
    "        # No similar words found; return the original word\n",
    "        return word\n",
    "\n",
    "    # Step 2: Rank similar words using Stupid Backoff\n",
    "    word_scores = []\n",
    "    for candidate in similar_words:\n",
    "        # Add the candidate to the context for scoring\n",
    "        sequence_tokens = (context.split() + [candidate])\n",
    "        sequence = \" \".join(sequence_tokens)\n",
    "        prob = sentence_probability_with_backoff(sequence, ngram_models, alpha)\n",
    "        word_scores.append((candidate, prob))\n",
    "\n",
    "    # Step 3: Return the word with the highest score\n",
    "    word_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Step 4: Display the top-k ranked results\n",
    "    print(f\"\\nTop-{len(word_scores)} Predictions for '{word}':\")\n",
    "    for rank, (candidate, prob) in enumerate(word_scores, start=1):\n",
    "        print(f\"  {rank}. {candidate} - Probability: {prob:.10e}\")  # Scientific notation\n",
    "    \n",
    "    return word_scores[0][0] if word_scores else word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for building first 3 n-gram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_models(filepath):\n",
    "    \"\"\"\n",
    "    Build n-gram models for 1-gram, 2-gram, and 3-gram.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the dataset.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of n-gram models (ngram_counts, n_minus_1_counts, vocab_size) for n = 1, 2, 3.\n",
    "    \"\"\"\n",
    "    corpus = load_data(filepath)\n",
    "    ngram_models = {}\n",
    "    \n",
    "    for n in range(1, 4):  # 1-gram, 2-gram, 3-gram\n",
    "        ngram_counts, n_minus_1_counts, vocab_size = build_ngram_model(corpus, n)\n",
    "        ngram_models[n] = (ngram_counts, n_minus_1_counts, vocab_size)\n",
    "    \n",
    "    return ngram_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function for doing the exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download tedtalk.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted File ID: 1ZFXJVav0rZ0V2TadMuY0TxWuwxkhN-nq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ZFXJVav0rZ0V2TadMuY0TxWuwxkhN-nq\n",
      "To: e:\\2_LEARNING_BKU\\2_File_2\\K22_HK242\\CO3085_NLP\\BT\\Lab03\\tedtalk.txt\n",
      "100%|██████████| 40.3M/40.3M [00:04<00:00, 9.09MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download tedtalk\n",
    "url = \"https://drive.google.com/file/d/1ZFXJVav0rZ0V2TadMuY0TxWuwxkhN-nq/view?usp=sharing\"\n",
    "\n",
    "def download_from_google_drive(url, output_filename=None):\n",
    "    # Extract file ID using regex\n",
    "    match = re.search(r\"/d/([^/]+)\", url)\n",
    "    if not match:\n",
    "        print(\"Error: Could not extract file ID from the URL.\")\n",
    "        return\n",
    "    \n",
    "    file_id = match.group(1)\n",
    "    print(f\"Extracted File ID: {file_id}\")\n",
    "\n",
    "    download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "    if output_filename:\n",
    "        gdown.download(download_url, output_filename, quiet=False)\n",
    "    else:\n",
    "        gdown.download(download_url, quiet=False)\n",
    "\n",
    "url = \"https://drive.google.com/file/d/1ZFXJVav0rZ0V2TadMuY0TxWuwxkhN-nq/view?usp=sharing\"\n",
    "download_from_google_drive(url, \"tedtalk.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with the results from In Class Exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building n-gram models...\n",
      "\n",
      "Comparison Results:\n",
      "\n",
      "Laplace Smoothing:\n",
      "1-gram - Correct: 5.360670754385347e-27, Incorrect: 5.360670754385346e-27\n",
      "  Higher Probability: Sentence 1 (Correct)\n",
      "  Probability Difference: 7.174648137343064e-43\n",
      "2-gram - Correct: 9.04981020727541e-29, Incorrect: 9.049810207275411e-29\n",
      "  Higher Probability: Sentence 2 (Incorrect)\n",
      "  Probability Difference: 1.1210387714598537e-44\n",
      "3-gram - Correct: 4.7232926503721375e-31, Incorrect: 4.723292650372137e-31\n",
      "  Higher Probability: Sentence 1 (Correct)\n",
      "  Probability Difference: 8.758115402030107e-47\n",
      "\n",
      "Stupid Backoff Smoothing:\n",
      "Correct: 1.456742136608319e-39, Incorrect: 1.4553198356546868e-39\n",
      "  Higher Probability: Sentence 1 (Correct)\n",
      "  Probability Difference: 1.4223009536322667e-42\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(os.getcwd(), \"tedtalk.txt\")\n",
    "\n",
    "print(\"Building n-gram models...\")\n",
    "ngram_models = build_ngram_models(dataset_path)\n",
    "\n",
    "# Example sentences for comparison\n",
    "correct_sentence = \"the cat sat on the mat\"\n",
    "incorrect_sentence = \"the mat sat on the cat\"\n",
    "\n",
    "# Compare results\n",
    "comparison_results = compare_sentences_with_smoothing(correct_sentence, incorrect_sentence, ngram_models)\n",
    "print(\"\\nComparison Results:\")\n",
    "for method, results in comparison_results.items():\n",
    "    print(f\"\\n{method} Smoothing:\")\n",
    "    if method == \"Laplace\":\n",
    "        # Loop each n-gram\n",
    "        for ngram, probs in results.items():\n",
    "            print(f\"{ngram} - Correct: {probs['sentence1']}, Incorrect: {probs['sentence2']}\")\n",
    "            print(f\"  Higher Probability: {probs['higher_probability']}\")\n",
    "            print(f\"  Probability Difference: {probs['probability_difference']}\")\n",
    "    elif method == \"Stupid Backoff\":\n",
    "        # Print result for Stupid Backoff\n",
    "        print(f\"Correct: {results['sentence1']}, Incorrect: {results['sentence2']}\")\n",
    "        print(f\"  Higher Probability: {results['higher_probability']}\")\n",
    "        print(f\"  Probability Difference: {results['probability_difference']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the newly built model to generate the next words for a given word sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input sequence: 'the cat'\n",
      "Tokens: ['the', 'cat']\n",
      "\n",
      "Searching for 3-grams with prefix: ('the', 'cat')\n",
      "Match found: ('the', 'cat', 'sleep'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'likes'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'came'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'scan.'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'scan'), Count: 2, Score: 0.000017\n",
      "Match found: ('the', 'cat', 'is'), Count: 8, Score: 0.000051\n",
      "Match found: ('the', 'cat', 'scans,'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'from'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'can'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'and'), Count: 2, Score: 0.000017\n",
      "Match found: ('the', 'cat', 'to'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'scanner,'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'eats'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'or'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'is.'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'limb,'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'comes'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'purring,'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'outweighs'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'face.'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'owner'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'i'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'in'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'was'), Count: 2, Score: 0.000017\n",
      "Match found: ('the', 'cat', 'people'), Count: 1, Score: 0.000011\n",
      "Match found: ('the', 'cat', 'sat'), Count: 0, Score: 0.000006\n",
      "Match found: ('the', 'cat', '</s>'), Count: 0, Score: 0.000006\n",
      "\n",
      "Searching for 2-grams with prefix: ('cat',)\n",
      "Match found: ('cat', 'scan,'), Count: 3, Score: 0.000023\n",
      "Match found: ('cat', 'in'), Count: 10, Score: 0.000062\n",
      "Match found: ('cat', 'scans'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'burning,'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'was'), Count: 4, Score: 0.000028\n",
      "Match found: ('cat', '♫'), Count: 2, Score: 0.000017\n",
      "Match found: ('cat', 'gave'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'fanciers'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'sleep'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'batting'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'likes'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'that'), Count: 3, Score: 0.000023\n",
      "Match found: ('cat', '2:'), Count: 2, Score: 0.000017\n",
      "Match found: ('cat', 'odor-saturated'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'from'), Count: 4, Score: 0.000028\n",
      "Match found: ('cat', 'saying,'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'if'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'everyday?'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'and'), Count: 14, Score: 0.000085\n",
      "Match found: ('cat', 'came'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'is'), Count: 15, Score: 0.000091\n",
      "Match found: ('cat', 'wants'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'on'), Count: 3, Score: 0.000023\n",
      "Match found: ('cat', 'brain,'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', '—'), Count: 2, Score: 0.000017\n",
      "Match found: ('cat', 'to'), Count: 2, Score: 0.000017\n",
      "Match found: ('cat', \"stevens'\"), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'scan'), Count: 6, Score: 0.000040\n",
      "Match found: ('cat', 'scan.'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'or'), Count: 5, Score: 0.000034\n",
      "Match found: ('cat', \"that's\"), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'asleep'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'corporation'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'litter'), Count: 2, Score: 0.000017\n",
      "Match found: ('cat', 'scans,'), Count: 3, Score: 0.000023\n",
      "Match found: ('cat', 'feeder.'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'can'), Count: 2, Score: 0.000017\n",
      "Match found: ('cat', 'transportation.'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'photo'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'video'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'scanner,'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'somewhere'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'person?'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'gut.'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'gut'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'piss,'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'eats'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'could'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'scan?\"'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'named'), Count: 2, Score: 0.000017\n",
      "Match found: ('cat', 'has'), Count: 3, Score: 0.000023\n",
      "Match found: ('cat', 'be?'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', '100'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'sitting'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'is.'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'lying'), Count: 2, Score: 0.000017\n",
      "Match found: ('cat', 'videos'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'psychologist,'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'go'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'fame,'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'running'), Count: 2, Score: 0.000017\n",
      "Match found: ('cat', 'locomotion'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'biomechanics,'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'limb'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'limbs'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'limb,'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'food'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'comes'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'purring,'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'fleas,'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'fleas'), Count: 3, Score: 0.000023\n",
      "Match found: ('cat', 'awakened,'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'outweighs'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'grizmo'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'prey'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'faces'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'it'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'a'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'face.'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'clinging'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'hunted'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'what'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'owner'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'i'), Count: 2, Score: 0.000017\n",
      "Match found: ('cat', 'with'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'videos.'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'experiment'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'system,'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'alive'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'dead.'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'will'), Count: 3, Score: 0.000023\n",
      "Match found: ('cat', 'lives'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'sex'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'people?'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'people'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'understands'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'souls.'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'sounds)'), Count: 2, Score: 0.000017\n",
      "Match found: ('cat', 'of'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'may'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'feet.'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'nearby.'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'videos,'), Count: 1, Score: 0.000011\n",
      "Match found: ('cat', 'sat'), Count: 0, Score: 0.000006\n",
      "Match found: ('cat', '</s>'), Count: 0, Score: 0.000006\n",
      "\n",
      "Top candidate words and scores:\n",
      "Word: is, Score: 0.000142\n",
      "Word: and, Score: 0.000102\n",
      "Word: in, Score: 0.000074\n",
      "Word: scan, Score: 0.000057\n",
      "Word: was, Score: 0.000045\n",
      "\n",
      "Top predictions for 'the cat':\n",
      "1. is - Score: 0.000142\n",
      "2. and - Score: 0.000102\n",
      "3. in - Score: 0.000074\n",
      "4. scan - Score: 0.000057\n",
      "5. was - Score: 0.000045\n"
     ]
    }
   ],
   "source": [
    "# Predict the next word\n",
    "sequence = \"the cat\"\n",
    "\n",
    "# Predict next words\n",
    "# I only search from 2 and 3-gram models as 1-gram contain less information\n",
    "predicted_words = predict_next_word(sequence, ngram_models, alpha=0.4, top_k=5)\n",
    "\n",
    "print(f\"\\nTop predictions for '{sequence}':\")\n",
    "for rank, (word, score) in enumerate(predicted_words, start=1):\n",
    "    print(f\"{rank}. {word} - Score: {score:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine with a function that calculates the distance between words to predict the correct word for a misspelled word position. (from difflib import get_close_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-5 Predictions for 'wonderfall':\n",
      "  1. wonderful - Probability: 6.5913879405e-21\n",
      "  2. wonderfully - Probability: 2.9877586682e-21\n",
      "  3. wonderfully. - Probability: 4.7175136867e-22\n",
      "  4. wonderful? - Probability: 4.7175136867e-22\n",
      "  5. wonderfully, - Probability: 1.5725045622e-22\n",
      "Misspelled Word: wonderfall\n",
      "Corrected Word: wonderful\n",
      "\n",
      "Top-5 Predictions for 'hhellp':\n",
      "  1. helps - Probability: 8.9527142795e-28\n",
      "  2. hell - Probability: 4.2397215200e-28\n",
      "  3. help - Probability: 2.4737207895e-28\n",
      "  4. shell - Probability: 1.5578511632e-28\n",
      "  5. he’ll - Probability: 2.3663561972e-29\n",
      "Misspelled Word: hhellp\n",
      "Corrected Word: helps\n"
     ]
    }
   ],
   "source": [
    "# Example vocabulary and models\n",
    "vocabulary = set(load_data(\"tedtalk.txt\"))\n",
    "\n",
    "# Example misspelled word correction\n",
    "misspelled_word = \"wonderfall\"\n",
    "context = \"I love this\"\n",
    "corrected_word = correct_misspelled_word(misspelled_word, vocabulary, ngram_models, context, alpha=0.4, top_k=5)\n",
    "\n",
    "print(f\"Misspelled Word: {misspelled_word}\")\n",
    "print(f\"Corrected Word: {corrected_word}\")\n",
    "\n",
    "misspelled_word = \"hhellp\"\n",
    "context = \"Thankyou very much for your\"\n",
    "corrected_word = correct_misspelled_word(misspelled_word, vocabulary, ngram_models, context, alpha=0.4, top_k=5)\n",
    "\n",
    "print(f\"Misspelled Word: {misspelled_word}\")\n",
    "print(f\"Corrected Word: {corrected_word}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
