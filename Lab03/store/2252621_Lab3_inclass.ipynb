{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Language Model and Application for Spelling Error Correction**\n",
    "\n",
    "**Objective**: Develop a simple English syntax error correction program.\n",
    "\n",
    "a) Build a language model based on n-grams using the Laplace smoothing method for the following models:\n",
    "\n",
    "- 1-gram\n",
    "- 2-gram\n",
    "- 3-gram\n",
    "\n",
    "b) Calculate the probability of a sentence and compute the Perplexity of a sentence based on 1-gram, 2-gram, and 3-gram models.\n",
    "\n",
    "c) Analyze the results (Provide your own examples of spelling errors and calculate the probability of two similar sentences, where one has the correct word order and the other has an incorrect word order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\python312\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: gdown in c:\\python312\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\python312\\lib\\site-packages (from wordcloud) (2.1.3)\n",
      "Requirement already satisfied: pillow in c:\\python312\\lib\\site-packages (from wordcloud) (10.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\python312\\lib\\site-packages (from wordcloud) (3.9.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\python312\\lib\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\python312\\lib\\site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\python312\\lib\\site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python312\\lib\\site-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python312\\lib\\site-packages (from matplotlib->wordcloud) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python312\\lib\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python312\\lib\\site-packages (from matplotlib->wordcloud) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python312\\lib\\site-packages (from matplotlib->wordcloud) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->wordcloud) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python312\\lib\\site-packages (from matplotlib->wordcloud) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests[socks]->gdown) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests[socks]->gdown) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\python312\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install gdown matplotlib wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable being used: c:\\Python312\\python.exe\n",
      "Python version: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]\n",
      "Operating System: Windows\n",
      "OS Version: 10.0.19045\n",
      "OS Release: 10\n",
      "Machine: AMD64\n",
      "Running in Visual Studio Code\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# import platform\n",
    "\n",
    "# # Python environment details\n",
    "# print(\"Python executable being used:\", sys.executable)\n",
    "# print(\"Python version:\", sys.version)\n",
    "\n",
    "# # Operating System details\n",
    "# print(\"Operating System:\", platform.system())\n",
    "# print(\"OS Version:\", platform.version())\n",
    "# print(\"OS Release:\", platform.release())\n",
    "\n",
    "# # Machine and architecture details\n",
    "# print(\"Machine:\", platform.machine())\n",
    "\n",
    "# # Visual Studio Code details (based on environment variable)\n",
    "# vscode_info = os.environ.get('VSCODE_PID', None)\n",
    "# if vscode_info:\n",
    "#     print(\"Running in Visual Studio Code\")\n",
    "# else:\n",
    "#     print(\"Not running in Visual Studio Code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gdown\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    \"\"\"\n",
    "    Load and preprocess text data from a file.\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        sentences = file.readlines()\n",
    "    \n",
    "    # Add <s> and </s> to each sentence and tokenize\n",
    "    tokens = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip().lower()\n",
    "        if sentence:  \n",
    "            tokens.extend([\"<s>\"] + sentence.split() + [\"</s>\"])\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for building a specific n-gram model with given corpus and n value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_model(corpus, n):\n",
    "    \"\"\"\n",
    "    Build an n-gram model from a given corpus and given n\n",
    "    \"\"\"\n",
    "    ngram_counts = defaultdict(int)\n",
    "    n_minus_1_counts = defaultdict(int)\n",
    "    vocabulary = set(corpus)\n",
    "\n",
    "    for i in range(len(corpus) - n + 1):\n",
    "        ngram = tuple(corpus[i:i + n])\n",
    "        n_minus_1_gram = tuple(corpus[i:i + n - 1])\n",
    "        ngram_counts[ngram] += 1\n",
    "        n_minus_1_counts[n_minus_1_gram] += 1\n",
    "\n",
    "    return ngram_counts, n_minus_1_counts, len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for computing sentence probabilities with laplace smoothing\n",
    "\n",
    "1. **Understanding N-gram Probabilities**:\n",
    "   - An n-gram is a sequence of `n` tokens (words).\n",
    "   - The probability of an n-gram with Laplace smoothing is computed as:\n",
    "   - \n",
    "     $\n",
    "     P(w_i | w_{i-(n-1)}, \\ldots, w_{i-1}) = \\frac{\\text{Count}(w_{i-(n-1)}, \\ldots, w_i) + 1}{\\text{Count}(w_{i-(n-1)}, \\ldots, w_{i-1}) + V}\n",
    "     $\n",
    "\n",
    "     Where:\n",
    "     - $\\text{Count}(w_{i-(n-1)}, \\ldots, w_i)$: Count of the n-gram in the training data.\n",
    "     - $\\text{Count}(w_{i-(n-1)}, \\ldots, w_{i-1})$: Count of the (n-1)-gram prefix.\n",
    "     - $V$: Vocabulary size (total number of unique tokens in the training data).\n",
    "\n",
    "2. **Handling Zero Counts**:\n",
    "   - If the n-gram or its prefix does not appear in the training data, the smoothing process ensures a non-zero probability by adding 1 to the numerator and the vocabulary size $V$ to the denominator.\n",
    "\n",
    "3. **Sentence Probability**:\n",
    "   - A sentence's probability is the product of probabilities for all n-grams in the sentence:\n",
    "   - \n",
    "     $\n",
    "     P(\\text{sentence}) = \\prod_{i=1}^{N} P(w_i | w_{i-(n-1)}, \\ldots, w_{i-1})\n",
    "     $\n",
    "\n",
    "     Here, the sentence is tokenized with start (`<s>`) and end (`</s>`) markers to capture context at the boundaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_laplace_probability(ngram, ngram_counts, n_minus_1_counts, vocab_size):\n",
    "    \"\"\"\n",
    "    Compute the Laplace smoothed probability of an n-gram.\n",
    "    \"\"\"\n",
    "    ngram_count = ngram_counts[ngram]\n",
    "    n_minus_1_count = n_minus_1_counts[ngram[:-1]] if len(ngram) > 1 else sum(ngram_counts.values())\n",
    "    return (ngram_count + 1) / (n_minus_1_count + vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_probability(sentence, ngram_counts, n_minus_1_counts, vocab_size, n):\n",
    "    \"\"\"\n",
    "    Compute the probability of a sentence using an n-gram model with laplace smoothing\n",
    "    \"\"\"\n",
    "    tokens = [\"<s>\"] + sentence.split() + [\"</s>\"]\n",
    "    prob = 1.0\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        ngram = tuple(tokens[i:i + n])\n",
    "        prob *= compute_laplace_probability(ngram, ngram_counts, n_minus_1_counts, vocab_size)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for computing perplexity with the used of laplace probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(sentence, ngram_counts, n_minus_1_counts, vocab_size, n):\n",
    "    \"\"\"\n",
    "    Compute the perplexity of a sentence using an n-gram model.\n",
    "    \"\"\"\n",
    "    tokens = [\"<s>\"] + sentence.split() + [\"</s>\"]\n",
    "    prob = 0.0\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        ngram = tuple(tokens[i:i + n])\n",
    "        prob += math.log(compute_laplace_probability(ngram, ngram_counts, n_minus_1_counts, vocab_size))\n",
    "    prob = -prob / len(tokens)\n",
    "    return math.exp(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for building first 3 n-gram models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_models(filepath):\n",
    "    \"\"\"\n",
    "    Build n-gram models for 1-gram, 2-gram, and 3-gram.\n",
    "    \"\"\"\n",
    "    corpus = load_data(filepath)\n",
    "    ngram_models = {}\n",
    "    \n",
    "    for n in range(1, 4): \n",
    "        ngram_counts, n_minus_1_counts, vocab_size = build_ngram_model(corpus, n)\n",
    "        ngram_models[n] = (ngram_counts, n_minus_1_counts, vocab_size)\n",
    "    \n",
    "    return ngram_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for calculating the probability and the perplexity of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentence(sentence, ngram_models):\n",
    "    \"\"\"\n",
    "    Analyze a sentence by computing its probability and perplexity for 1-gram, 2-gram, and 3-gram models.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for n, (ngram_counts, n_minus_1_counts, vocab_size) in ngram_models.items():\n",
    "        prob = sentence_probability(sentence, ngram_counts, n_minus_1_counts, vocab_size, n)\n",
    "        perplexity = compute_perplexity(sentence, ngram_counts, n_minus_1_counts, vocab_size, n)\n",
    "        results[n] = {\"probability\": prob, \"perplexity\": perplexity}\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for comparing 2 sentences by analyzing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sentences(correct_sentence, incorrect_sentence, ngram_models):\n",
    "    \"\"\"\n",
    "    Compare probabilities and perplexities of two sentences: one correct and one incorrect.\n",
    "    \"\"\"\n",
    "    correct_results = analyze_sentence(correct_sentence, ngram_models)\n",
    "    incorrect_results = analyze_sentence(incorrect_sentence, ngram_models)\n",
    "\n",
    "    comparison = {}\n",
    "    for n in correct_results.keys():\n",
    "        # Extract probabilities and perplexities for both sentences\n",
    "        correct_prob = correct_results[n][\"probability\"]\n",
    "        incorrect_prob = incorrect_results[n][\"probability\"]\n",
    "        correct_perplexity = correct_results[n][\"perplexity\"]\n",
    "        incorrect_perplexity = incorrect_results[n][\"perplexity\"]\n",
    "\n",
    "        if correct_prob > incorrect_prob:\n",
    "            higher_sentence = \"Correct Sentence\"\n",
    "        elif incorrect_prob > correct_prob:\n",
    "            higher_sentence = \"Incorrect Sentence\"\n",
    "        else:\n",
    "            higher_sentence = \"Both sentences have equal probability\"\n",
    "\n",
    "        # Store comparison results\n",
    "        comparison[n] = {\n",
    "            \"correct\": {\n",
    "                \"probability\": correct_prob,\n",
    "                \"perplexity\": correct_perplexity,\n",
    "            },\n",
    "            \"incorrect\": {\n",
    "                \"probability\": incorrect_prob,\n",
    "                \"perplexity\": incorrect_perplexity,\n",
    "            },\n",
    "            \"higher_probability\": higher_sentence,\n",
    "            \"probability_difference\": abs(correct_prob - incorrect_prob),\n",
    "            \"perplexity_difference\": abs(correct_perplexity - incorrect_perplexity),\n",
    "        }\n",
    "\n",
    "    return comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Main functions for the Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: Develop a simple English syntax error correction program.\n",
    "\n",
    "a) Build a language model based on n-grams using the Laplace smoothing method for the following models:\n",
    "\n",
    "- 1-gram\n",
    "- 2-gram\n",
    "- 3-gram\n",
    "\n",
    "b) Calculate the probability of a sentence and compute the Perplexity of a sentence based on 1-gram, 2-gram, and 3-gram models.\n",
    "\n",
    "c) Analyze the results (Provide your own examples of spelling errors and calculate the probability of two similar sentences, where one has the correct word order and the other has an incorrect word order)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the tedtalk from public link google drive to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted File ID: 1ZFXJVav0rZ0V2TadMuY0TxWuwxkhN-nq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ZFXJVav0rZ0V2TadMuY0TxWuwxkhN-nq\n",
      "To: e:\\2_LEARNING_BKU\\2_File_2\\K22_HK242\\CO3085_NLP\\BT\\Lab03\\tedtalk.txt\n",
      "100%|██████████| 40.3M/40.3M [00:15<00:00, 2.65MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download tedtalk\n",
    "url = \"https://drive.google.com/file/d/1ZFXJVav0rZ0V2TadMuY0TxWuwxkhN-nq/view?usp=sharing\"\n",
    "\n",
    "def download_from_google_drive(url, output_filename=None):\n",
    "    # Extract file ID using regex\n",
    "    match = re.search(r\"/d/([^/]+)\", url)\n",
    "    if not match:\n",
    "        print(\"Error: Could not extract file ID from the URL.\")\n",
    "        return\n",
    "    \n",
    "    file_id = match.group(1)\n",
    "    print(f\"Extracted File ID: {file_id}\")\n",
    "\n",
    "    download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "    if output_filename:\n",
    "        gdown.download(download_url, output_filename, quiet=False)\n",
    "    else:\n",
    "        gdown.download(download_url, quiet=False)\n",
    "\n",
    "url = \"https://drive.google.com/file/d/1ZFXJVav0rZ0V2TadMuY0TxWuwxkhN-nq/view?usp=sharing\"\n",
    "download_from_google_drive(url, \"tedtalk.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Build n-gram models using Laplace smoothing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building n-gram models...\n"
     ]
    }
   ],
   "source": [
    "# Path \n",
    "dataset_path = os.path.join(os.getcwd(), \"tedtalk.txt\")\n",
    "\n",
    "# n-gram models\n",
    "print(\"Building n-gram models...\")\n",
    "ngram_models = build_ngram_models(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N-gram Counts for Each Model:\n",
      "\n",
      "1-gram Model Counts:\n",
      "('<s>',): 4005\n",
      "('thank',): 5095\n",
      "('you',): 85456\n",
      "('so',): 50404\n",
      "('much,',): 373\n",
      "('chris.',): 56\n",
      "('and',): 238523\n",
      "(\"it's\",): 32598\n",
      "('truly',): 654\n",
      "('a',): 170018\n",
      "... (Total unique 1-grams: 175986)\n",
      "\n",
      "2-gram Model Counts:\n",
      "('<s>', 'thank'): 22\n",
      "('thank', 'you'): 1515\n",
      "('you', 'so'): 320\n",
      "('so', 'much,'): 108\n",
      "('much,', 'chris.'): 4\n",
      "('chris.', 'and'): 4\n",
      "('and', \"it's\"): 3575\n",
      "(\"it's\", 'truly'): 14\n",
      "('truly', 'a'): 19\n",
      "('a', 'great'): 1196\n",
      "... (Total unique 2-grams: 1915064)\n",
      "\n",
      "3-gram Model Counts:\n",
      "('<s>', 'thank', 'you'): 12\n",
      "('thank', 'you', 'so'): 257\n",
      "('you', 'so', 'much,'): 22\n",
      "('so', 'much,', 'chris.'): 3\n",
      "('much,', 'chris.', 'and'): 2\n",
      "('chris.', 'and', \"it's\"): 1\n",
      "('and', \"it's\", 'truly'): 3\n",
      "(\"it's\", 'truly', 'a'): 4\n",
      "('truly', 'a', 'great'): 1\n",
      "('a', 'great', 'honor'): 8\n",
      "... (Total unique 3-grams: 4649030)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nN-gram Counts for Each Model:\")\n",
    "for n, (ngram_counts, _, _) in ngram_models.items():\n",
    "    print(f\"\\n{n}-gram Model Counts:\")\n",
    "    \n",
    "    for ngram, count in list(ngram_counts.items())[:10]: \n",
    "        print(f\"{ngram}: {count}\")\n",
    "    \n",
    "    print(f\"... (Total unique {n}-grams: {len(ngram_counts)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Calculate the probability and perplexity of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentence: That man over there is so handsome\n",
      "\n",
      "Sentence Analysis:\n",
      "\n",
      "1-gram Model:\n",
      "Probability: 6.426880047209636e-33\n",
      "Perplexity: 3774.7558540347018\n",
      "\n",
      "2-gram Model:\n",
      "Probability: 3.3126875602593266e-34\n",
      "Perplexity: 5247.832285059609\n",
      "\n",
      "3-gram Model:\n",
      "Probability: 6.727572757238024e-35\n",
      "Perplexity: 6264.762651741025\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = \"That man over there is so handsome\"\n",
    "\n",
    "print(\"Sample sentence:\", sample_sentence)\n",
    "\n",
    "result = analyze_sentence(sample_sentence, ngram_models)\n",
    "print(\"\\nSentence Analysis:\")\n",
    "for n, values in result.items():\n",
    "    print(f\"\\n{n}-gram Model:\")\n",
    "    print(f\"Probability: {values['probability']}\")\n",
    "    print(f\"Perplexity: {values['perplexity']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Analyze the results (Provide your own examples of spelling errors and calculate the probability of two similar sentences, where one has the correct word order and the other has an incorrect word order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Correct vs Incorrect Sentences:\n",
      "\n",
      "1-gram Model:\n",
      "Correct Sentence - Probability: 5.360671e-27, Perplexity: 1922.4170439452398114\n",
      "Incorrect Sentence - Probability: 5.360671e-27, Perplexity: 1922.4170439452432220\n",
      "Higher Probability: Correct Sentence\n",
      "Probability Difference: 7.174648e-43\n",
      "Perplexity Difference: 0.0000000000034106\n",
      "\n",
      "2-gram Model:\n",
      "Correct Sentence - Probability: 9.049810e-29, Perplexity: 3201.9906991856773857\n",
      "Incorrect Sentence - Probability: 9.049810e-29, Perplexity: 3201.9906991856828427\n",
      "Higher Probability: Incorrect Sentence\n",
      "Probability Difference: 1.121039e-44\n",
      "Perplexity Difference: 0.0000000000054570\n",
      "\n",
      "3-gram Model:\n",
      "Correct Sentence - Probability: 4.723293e-31, Perplexity: 6176.1721563688815877\n",
      "Incorrect Sentence - Probability: 4.723293e-31, Perplexity: 6176.1721563688815877\n",
      "Higher Probability: Correct Sentence\n",
      "Probability Difference: 8.758115e-47\n",
      "Perplexity Difference: 0.0000000000000000\n"
     ]
    }
   ],
   "source": [
    "# Example sentences for comparison\n",
    "correct_sentence_example = \"the cat sat on the mat\"  \n",
    "incorrect_sentence = \"the mat sat on the cat\"\n",
    "\n",
    "# Compare probabilities and perplexities\n",
    "comparison = compare_sentences(correct_sentence_example, incorrect_sentence, ngram_models)\n",
    "\n",
    "# Display comparison results\n",
    "print(\"\\nComparison of Correct vs Incorrect Sentences:\")\n",
    "for n, results in comparison.items():\n",
    "    print(f\"\\n{n}-gram Model:\")\n",
    "    print(f\"Correct Sentence - Probability: {results['correct']['probability']:.6e}, Perplexity: {results['correct']['perplexity']:.16f}\")\n",
    "    print(f\"Incorrect Sentence - Probability: {results['incorrect']['probability']:.6e}, Perplexity: {results['incorrect']['perplexity']:.16f}\")\n",
    "    print(f\"Higher Probability: {results['higher_probability']}\")\n",
    "    print(f\"Probability Difference: {results['probability_difference']:.6e}\")\n",
    "    print(f\"Perplexity Difference: {results['perplexity_difference']:.16f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
