# NLP_Lab

Welcome to the **Natural Language Processing Lab Series**!  
This repository contains structured and hands-on labs designed to help you build a solid foundation in NLP - from basic preprocessing to advanced neural architectures.

---

## ðŸ”¬ Lab Overview

Below is the list of labs covered in this course:

| Lab    | Topic                                 | Short Description                                               |
|:-------|:--------------------------------------|:----------------------------------------------------------------|
| 01  | Web Scraping                          | Extract data from websites using requests and BeautifulSoup.    |
| 02  | Exploring and Preprocessing Text Data | Clean and normalize text data for NLP tasks.                    |
| 03  | Language Models                       | Understand and implement probabilistic language models.         |
| 04  | Vector Semantics and Embeddings       | Represent words as vectors using co-occurrence-based methods.   |
| 05  | Word Embeddings                       | Use dense word vectors like Word2Vec, GloVe, FastText.          |
| 06  | Linear - Logistic Regression          | Apply linear and logistic regression for NLP classification.    |
| 08  | Neural Networks                       | Build feedforward neural networks for text tasks.               |
| 09  | Recurrent Neural Networks (RNNs)      | Model sequences and time-series using RNNs.                     |
| 10 | Sequence-to-Sequence (Seq2Seq)        | Develop encoder-decoder architectures for NLP generation.       |
| 11 | Transformer                           | Explore the Transformer architecture used in modern NLP models. |

---

## ðŸš€ Getting Started

Clone this repository:
```bash
git clone https://github.com/your-username/NLP_Lab.git
cd NLP_Lab
```

---

## ðŸ“š License

This repository is for **educational purposes** only. Use freely and responsibly.

---
