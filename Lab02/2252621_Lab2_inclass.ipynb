{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1scE5rBNAR2G"
   },
   "source": [
    "# In-class Lab 2: Text Data Preprocessing\n",
    "**Overview:** In this lesson, we will build a text preprocessing pipeline for English text, which includes: data cleaning, converting to lowercase, removing punctuation, tokenization, removing stop words, and stemming. The exercise requires knowledge and programming skills in Python using libraries such as string, re, nltk, and numpy.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G8XZPuMAR2T"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8ijK-PShAR2V"
   },
   "outputs": [],
   "source": [
    "import string # used for preprocessing\n",
    "import re # used for preprocessing\n",
    "import nltk # the Natural Language Toolkit, used for preprocessing\n",
    "import numpy as np # used for managing NaNs\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize # used for preprocessing\n",
    "from nltk.corpus import stopwords # used for preprocessing\n",
    "from nltk.stem import WordNetLemmatizer # used for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable being used: c:\\Python312\\python.exe\n",
      "Python version: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]\n",
      "Operating System: Windows\n",
      "OS Version: 10.0.19045\n",
      "OS Release: 10\n",
      "Machine: AMD64\n",
      "Running in Visual Studio Code\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import platform\n",
    "\n",
    "# Python environment details\n",
    "print(\"Python executable being used:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "# Operating System details\n",
    "print(\"Operating System:\", platform.system())\n",
    "print(\"OS Version:\", platform.version())\n",
    "print(\"OS Release:\", platform.release())\n",
    "\n",
    "# Machine and architecture details\n",
    "print(\"Machine:\", platform.machine())\n",
    "\n",
    "# Visual Studio Code details (based on environment variable)\n",
    "vscode_info = os.environ.get('VSCODE_PID', None)\n",
    "if vscode_info:\n",
    "    print(\"Running in Visual Studio Code\")\n",
    "else:\n",
    "    print(\"Not running in Visual Studio Code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0DQgAkWAR2W"
   },
   "source": [
    "## Question 1: Exploring the Dataset\n",
    "\n",
    "The raw text data that needs preprocessing is in the file \"wiki.txt\". This file contains short documents (docs), with each document on a separate line. In this question, we will explore the following:\n",
    "\n",
    "- The number of docs in the corpus\n",
    "- Observing a few docs from the corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GsbV9GSEAR2X",
    "outputId": "e5590b0b-38c0-4f34-bd1b-b202ded3338d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Documents from the Dataset:\n",
      "Document 1: Madhuca utilis is a tree in the Sapotaceae family. It grows up to 40 metres (130 ft) tall, with a trunk diameter of up to 70 centimetres (28 in). The bark is greyish brown. The fruits are ellipsoid, up to 5.5 centimetres (2.2 in) long. The specific epithet utilis is from the Latin meaning \\\"useful\\\", referring to the timber. Habitat is swamps and lowland kerangas forests. M. utilis is found in Sumatra, Peninsular Malaysia and Borneo.\n",
      "\n",
      "Document 2: The Lycée Edmond Perrier (Edmond Perrier high school) is a general and technical secondary education institution, located in Tulle, Correze. It is dedicated to zoologist Edmond Perrier, born in Tulle in 1844. It was built by Anatole de Baudot, and has many similarities with the Lycée Lakanal, due to the same architect. His motto is \\\"Sint rupes virtutis iter\\\", identical to that of Tulle which means \\\"The difficulties are the path of virtue\\\".\n",
      "\n",
      "Document 3: Shareh Khvor (Persian: شره خور‎‎) is a village in Bask-e Kuleseh Rural District, in the Central District of Sardasht County, West Azerbaijan Province, Iran. At the 2006 census, its population was 14, in 4 families.\n",
      "\n",
      "Document 4: St. Rose Roman Catholic Church Complex is a Roman Catholic church complex located at Lima in Livingston County, New York. The complex consists of four contributing buildings: 1) St. Rose Church, constructed 1870-1873; 2) Brendan Hall, constructed in 1894 as a parochial school; 3) rectory; and 4) convent. It was listed on the National Register of Historic Places in 1988.\n",
      "\n",
      "Document 5: Langangen is a village in Porsgrunn municipality, Telemark county, in Norway. Langangen borders to Larvik municipality and Vestfold county. Its population is 499 (2009 Census). Langangen was earlier divided by European route E18 but in 1979 the road was led over Langangen bridge. Langangen has its own elementary school and chapel.\n",
      "\n",
      "Total Number of Documents: 2362\n"
     ]
    }
   ],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "# Step 1: Read the dataset\n",
    "with open(\"wiki.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    docs = file.readlines()\n",
    "\n",
    "# Step 2: Observing a few documents\n",
    "print(\"Sample Documents from the Dataset:\")\n",
    "\n",
    "for i, doc in enumerate(docs[:5], start=1):\n",
    "    print(f\"Document {i}: {doc}\")\n",
    "\n",
    "# Step 3: Count the number of documents\n",
    "print(f\"Total Number of Documents: {len(docs)}\")\n",
    "\n",
    "#### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Building Text Processing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6I8R30NAR2c"
   },
   "source": [
    "### Question 2.1: Building a Data Cleaning Function\n",
    "\n",
    "**Description:** The function removes digits and keeps only the characters \"A-Za-z(),!?\\'\\`\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "80LZzOxCAR2d"
   },
   "outputs": [],
   "source": [
    "# clean text\n",
    "def clean_text(text):\n",
    "    #### YOUR CODE HERE ####\n",
    "    text_clean = re.sub(r'[^A-Za-z(),!?\\`\\' ]', \"\", text)\n",
    "    return text_clean\n",
    "    #### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLyDqwtcAR2d"
   },
   "source": [
    "### Question 2.2: Function to Convert Text to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "v5N6q83DAR2e"
   },
   "outputs": [],
   "source": [
    "# make all text lowercase\n",
    "#### YOUR CODE HERE ####\n",
    "# Use the lower() funtion from Python\n",
    "def text_lowercase(text):\n",
    "    lower_text = text.lower()\n",
    "    return lower_text\n",
    "\n",
    "#### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vkzajg44AR2e"
   },
   "source": [
    "### Question 2.3: Building a Function to Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lLFWvQRLAR2f"
   },
   "outputs": [],
   "source": [
    "# remove punctuation because\n",
    "# - punctuation does not contain meaning \n",
    "# - remove this would reduce the size of the data\n",
    "# - use the replace() function\n",
    "def remove_punctuation(text):\n",
    "    #### YOUR CODE HERE ####\n",
    "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    return text.translate(translator)\n",
    "    #### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_ocSyA9AR2f"
   },
   "source": [
    "### Question 2.4: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ru8lNWuDAR2g"
   },
   "outputs": [],
   "source": [
    "# tokenize\n",
    "# - For English: NLTK, SpaCy, TextBlob\n",
    "# - For Vietnamese: VnCoreNLP, underthesea, coccoc-tokenizer\n",
    "def tokenize(text):\n",
    "    #### YOUR CODE HERE ####    \n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "    \n",
    "    #### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9L8rJildAR2g"
   },
   "source": [
    "### Question 2.5: Removing Stopwords\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-03fXud4AR2h"
   },
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "# - nltk library\n",
    "# - npm install vietnamese-stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#### YOUR CODE HERE ####\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word.lower() not in stop_words]\n",
    "#### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVXH3PorAR2h"
   },
   "source": [
    "### Question 2.6: Building a Lemmatization Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hNb3hemPAR2i"
   },
   "outputs": [],
   "source": [
    "# lemmatize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#### YOUR CODE HERE ####\n",
    "def lemmatize(tokens):\n",
    "    # Lemmatize each word and keep the original if no change occurs\n",
    "    lemmatized_text = []\n",
    "    for word in tokens:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word)\n",
    "        # If the word doesn't change, add it as is\n",
    "        if lemmatized_word == word:\n",
    "            lemmatized_text.append(word)\n",
    "        else:\n",
    "            lemmatized_text.append(lemmatized_word)\n",
    "    \n",
    "    return lemmatized_text\n",
    "    \n",
    "#### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pr3h3J4AR2i"
   },
   "source": [
    "### Question 2.7: Building a Preprocessing Function\n",
    "**Hint:** This function will call the functions written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lpM1j8v9AR2i"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = clean_text(sentence)\n",
    "    sentence = text_lowercase(sentence)\n",
    "    sentence = remove_punctuation(sentence)\n",
    "    tokens = tokenize(sentence)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = lemmatize(tokens)\n",
    "    return tokens\n",
    "\n",
    "def preprocess_document(document):\n",
    "    # Split the document into sentences\n",
    "    sentences = sent_tokenize(document)\n",
    "    \n",
    "    # Preprocess each sentence\n",
    "    preprocessed_sentences = [\" \".join(preprocess_sentence(sentence)) for sentence in sentences]\n",
    "    \n",
    "    # Reconstruct the preprocessed document\n",
    "    return \" \".join(preprocessed_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQJicZUrAR2j"
   },
   "source": [
    "## Question 3: Preprocessing for Input Text\n",
    "**Overview:** Using the functions above, preprocess the initial text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tSWwb3gsAR2j",
    "outputId": "5e0d91f7-f4cb-4998-e890-c38bb064377b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Sample Documents:\n",
      "Document 1: madhuca utilis tree sapotaceae family grows metre ft tall trunk diameter centimetre bark greyish brown fruit ellipsoid centimetre long specific epithet utilis latin meaning useful referring timber habitat swamp lowland kerangas forest utilis found sumatra peninsular malaysia borneo\n",
      "Document 2: lyce edmond perrier edmond perrier high school general technical secondary education institution located tulle correze dedicated zoologist edmond perrier born tulle built anatole de baudot many similarity lyce lakanal due architect motto sint rupes virtutis iter identical tulle mean difficulty path virtue\n",
      "Document 3: shareh khvor persian village baske kuleseh rural district central district sardasht county west azerbaijan province iran census population family\n",
      "Document 4: st rose roman catholic church complex roman catholic church complex located lima livingston county new york complex consists four contributing building st rose church constructed brendan hall constructed parochial school rectory convent listed national register historic place\n",
      "Document 5: langangen village porsgrunn municipality telemark county norway langangen border larvik municipality vestfold county population census langangen earlier divided european route e road led langangen bridge langangen elementary school chapel\n"
     ]
    }
   ],
   "source": [
    "# #### YOUR CODE HERE ####\n",
    "preprocessed_docs = [preprocess_document(doc) for doc in docs]\n",
    "\n",
    "# Example: Display preprocessed versions of the first 5 documents\n",
    "print(\"Preprocessed Sample Documents:\")\n",
    "for i, doc in enumerate(preprocessed_docs[:5], start=1):\n",
    "    print(f\"Document {i}: {doc}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
